{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mezlet/PPI-Inhibitors/blob/main/code/GNN_based_pipeline_Training_for_Predicting_small_molecule_inhibition_of_protein_complexes_ipynb_end_to_end.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5zy8pv8_EQa"
      },
      "source": [
        "**Set the Runtime->Change Runtime Type to GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLKfwNHlwnSE"
      },
      "source": [
        "# Protein 3d structure assessment with graph neural networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u /content/drive\n",
        "!rm -rf /content/drive\n",
        "%cd /content\n"
      ],
      "metadata": {
        "id": "E-cGEcP1jsvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_3U6PueCCgv",
        "outputId": "19199de6-5011-41b6-d6a5-0101744befff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'PPI-Inhibitors': No such file or directory\n",
            "Cloning into 'PPI-Inhibitors'...\n",
            "remote: Enumerating objects: 1341, done.\u001b[K\n",
            "remote: Total 1341 (delta 0), reused 0 (delta 0), pack-reused 1341 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1341/1341), 2.59 GiB | 44.77 MiB/s, done.\n",
            "Resolving deltas: 100% (417/417), done.\n",
            "Updating files: 100% (605/605), done.\n"
          ]
        }
      ],
      "source": [
        "#!rm -r Data\n",
        "!rm -r PPI-Inhibitors\n",
        "!git clone https://github.com/adibayaseen/PPI-Inhibitors\n",
        "#!pip install py3Dmol"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel\n",
        "!pip install rdkit biopython==1.81 torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 torch-geometric==2.5.3 tqdm==4.66.2 pandas==2.1.4 numpy==1.26.4 scikit-learn==1.3.2 matplotlib==3.8.3 seaborn==0.13.2 networkx==3.2.1 gdown\n"
      ],
      "metadata": {
        "id": "SOpJqASVkFMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc2da474-cf8f-46ab-da19-26d8c4bb383b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.3 setuptools-80.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "70afc73631dd4b139fc438c4129e045a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting biopython==1.81\n",
            "  Downloading biopython-1.81-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting torch==2.2.2\n",
            "  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision==0.17.2\n",
            "  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchaudio==2.2.2\n",
            "  Downloading torchaudio-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torch-geometric==2.5.3\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "Collecting tqdm==4.66.2\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting pandas==2.1.4\n",
            "  Downloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scikit-learn==1.3.2\n",
            "  Downloading scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting matplotlib==3.8.3\n",
            "  Downloading matplotlib-3.8.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Collecting networkx==3.2.1\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.2) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.5.3) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.5.3) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.5.3) (2.32.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.5.3) (3.2.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.5.3) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.1.4) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.8.3) (25.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.6.85)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.4) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric==2.5.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric==2.5.3) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric==2.5.3) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric==2.5.3) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric==2.5.3) (3.11)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric==2.5.3) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric==2.5.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric==2.5.3) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Downloading biopython-1.81-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.2.2-cp312-cp312-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "Downloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m206.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m237.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.8.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m144.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, rdkit, pandas, nvidia-cusolver-cu12, nvidia-cudnn-cu12, biopython, torch, scikit-learn, matplotlib, torchvision, torchaudio, torch-geometric\n",
            "\u001b[2K  Attempting uninstall: tqdm\n",
            "\u001b[2K    Found existing installation: tqdm 4.67.1\n",
            "\u001b[2K    Uninstalling tqdm-4.67.1:\n",
            "\u001b[2K      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: networkx\n",
            "\u001b[2K    Found existing installation: networkx 3.5\n",
            "\u001b[2K    Uninstalling networkx-3.5:\n",
            "\u001b[2K      Successfully uninstalled networkx-3.5\n",
            "\u001b[2K  Attempting uninstall: pandas\n",
            "\u001b[2K    Found existing installation: pandas 2.2.2\n",
            "\u001b[2K    Uninstalling pandas-2.2.2:\n",
            "\u001b[2K      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.8.0+cu126\n",
            "\u001b[2K    Uninstalling torch-2.8.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torch-2.8.0+cu126\n",
            "\u001b[2K  Attempting uninstall: scikit-learn\n",
            "\u001b[2K    Found existing installation: scikit-learn 1.6.1\n",
            "\u001b[2K    Uninstalling scikit-learn-1.6.1:\n",
            "\u001b[2K      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[2K  Attempting uninstall: matplotlib\n",
            "\u001b[2K    Found existing installation: matplotlib 3.10.0\n",
            "\u001b[2K    Uninstalling matplotlib-3.10.0:\n",
            "\u001b[2K      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[2K  Attempting uninstall: torchvision\n",
            "\u001b[2K    Found existing installation: torchvision 0.23.0+cu126\n",
            "\u001b[2K    Uninstalling torchvision-0.23.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "\u001b[2K  Attempting uninstall: torchaudio\n",
            "\u001b[2K    Found existing installation: torchaudio 2.8.0+cu126\n",
            "\u001b[2K    Uninstalling torchaudio-2.8.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [torch-geometric]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.66.2 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.10.1 requires pandas>=2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed biopython-1.81 matplotlib-3.8.3 networkx-3.2.1 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 pandas-2.1.4 rdkit-2025.9.1 scikit-learn-1.3.2 torch-2.2.2 torch-geometric-2.5.3 torchaudio-2.2.2 torchvision-0.17.2 tqdm-4.66.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "ef0341003fda4680b94636b181b58360"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PPI-Inhibitors\n",
        "!mkdir -p Data\n",
        "\n",
        "%cd Data\n",
        "!wget -q https://github.com/adibayaseen/PPI-Inhibitors/raw/01ad4975fb9133825b1bf9e71b64fcdaaa5e4d8b/Data/2p2iComplexPairs.txt\n",
        "!wget -q https://github.com/adibayaseen/PPI-Inhibitors/raw/01ad4975fb9133825b1bf9e71b64fcdaaa5e4d8b/Data/2p2iInhibitorsSMILES.txt\n",
        "!wget -q https://github.com/adibayaseen/PPI-Inhibitors/raw/2d6bd03422602ec19147870c487e64018b52660f/Data/WriteAllexamplesRandomBindersIdsAll_24JAN_Binary.txt\n",
        "!wget -q https://github.com/adibayaseen/PPI-Inhibitors/raw/b1e45884f61f792399abad2e4492f48083ab1093/Data/BindersWithComplexname.csv\n",
        "%cd .."
      ],
      "metadata": {
        "id": "6dliB1TskGg9",
        "outputId": "58a1873d-4c71-4395-c4cd-abd27464fc2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PPI-Inhibitors\n",
            "/content/PPI-Inhibitors/Data\n",
            "/content/PPI-Inhibitors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uOhzY0qAj-0",
        "outputId": "eeab2b06-5260-46e0-f3bd-2ba24abde74b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive'\n",
        "\n",
        "# Make folders\n",
        "!mkdir -p GNN-PPI-Inhibitor\n",
        "!gdown --id 1goeDiPZSKT1Xx3j00eNG9xlqYkLLv1gW -O GNN-PPI-Inhibitor/ProteinData_dict.pickle\n",
        "!gdown --id 1GOYEKLQCoGea9QQ72kujy0rdJKbUSYAE -O GNN-PPI-Inhibitor/DBD5_ProteinData_dict.pickle"
      ],
      "metadata": {
        "id": "VRBJi-5YkPqM",
        "outputId": "94208b1d-80fc-4789-c288-42fb20850959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1goeDiPZSKT1Xx3j00eNG9xlqYkLLv1gW\n",
            "To: /content/drive/MyDrive/GNN-PPI-Inhibitor/ProteinData_dict.pickle\n",
            "100% 34.6M/34.6M [00:00<00:00, 49.6MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GOYEKLQCoGea9QQ72kujy0rdJKbUSYAE\n",
            "From (redirected): https://drive.google.com/uc?id=1GOYEKLQCoGea9QQ72kujy0rdJKbUSYAE&confirm=t&uuid=ca1db167-c201-4b42-aedf-fab5e154181a\n",
            "To: /content/drive/MyDrive/GNN-PPI-Inhibitor/DBD5_ProteinData_dict.pickle\n",
            "100% 336M/336M [00:03<00:00, 100MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjV5-TPeGt-0",
        "outputId": "9c5b2f5c-b13d-4a80-ab22-c174ae590160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equivalent epochs in one iteration of data loader 1.06\n",
            "[[('15', '25', '33', '40', '79', '27', '23', '87', '61', '10'), ('-15', '-25', '-33', '-40', '-79', '-27', '-23', '-87', '-61', '-10')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('1', '39', '57', '76', '85', '92', '20', '37', '8', '4'), ('-1', '-39', '-57', '-76', '-85', '-92', '-20', '-37', '-8', '-4')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('28', '30', '32', '97', '99', '49', '47', '61', '31', '61'), ('-28', '-30', '-32', '-97', '-99', '-49', '-47', '-61', '-31', '-61')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('19', '45', '62', '64', '80', '10', '23', '10', '29', '8'), ('-19', '-45', '-62', '-64', '-80', '-10', '-23', '-10', '-29', '-8')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('0', '24', '46', '54', '77', '27', '37', '88', '27', '56'), ('0', '-24', '-46', '-54', '-77', '-27', '-37', '-88', '-27', '-56')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('35', '36', '48', '90', '96', '59', '4', '91', '49', '7'), ('-35', '-36', '-48', '-90', '-96', '-59', '-4', '-91', '-49', '-7')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('3', '17', '22', '34', '58', '37', '70', '93', '88', '75'), ('-3', '-17', '-22', '-34', '-58', '-37', '-70', '-93', '-88', '-75')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('6', '42', '68', '84', '86', '9', '89', '69', '66'), ('-6', '-42', '-68', '-84', '-86', '-9', '-89', '-69', '-66')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1])]\n",
            "[[('13', '44', '50', '63', '67', '89', '8', '9', '94'), ('-13', '-44', '-50', '-63', '-67', '-89', '-8', '-9', '-94')], tensor([0, 0, 0, 0, 0, 1, 1, 1, 1])]\n",
            "[[('18', '26', '71', '82', '59', '12', '29', '38', '70'), ('-18', '-26', '-71', '-82', '-59', '-12', '-29', '-38', '-70')], tensor([0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "[[('2', '52', '60', '78', '21', '83', '31', '21', '21'), ('-2', '-52', '-60', '-78', '-21', '-83', '-31', '-21', '-21')], tensor([0, 0, 0, 0, 1, 1, 1, 1, 1])]\n",
            "['80', '51', '1', '22', '30', '48', '14', '35', '27', '52', '7', '73', '83', '23', '29', '41', '91', '69', '12', '69', '68', '11', '76', '40', '7', '28', '29', '28', '74', '66', '38', '59', '78', '83', '18', '14', '66', '21', '8', '43', '90', '72', '92', '25', '46', '64', '64', '36', '64', '92', '57', '44', '5', '97', '75', '31', '3', '68', '94', '92', '67', '54', '14', '21', '44', '31', '57', '82', '72', '72', '45', '1', '3', '48', '12', '32', '38', '3', '53', '10', '64', '27', '75', '76', '31', '4', '45', '74', '96', '81', '30', '33', '59', '50', '69', '80', '3', '58', '94', '71']\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Jan  9 16:43:15 2024\n",
        "\n",
        "@author: u1876024\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "import numpy as np\n",
        "\n",
        "class BalancedDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom dataset class that creates a balanced dataset from imbalanced data.\n",
        "    This dataset calculates sample weights inversely proportional to class frequencies,\n",
        "    which can be used with a WeightedRandomSampler to achieve balanced batches.\n",
        "\n",
        "    NOTE: As it involves stochastic sampling, there is a chance that a few training examples are actually never selected.\n",
        "\n",
        "    Attributes:\n",
        "        data (array-like): The input data. Can be a list, NumPy array, or PyTorch tensor.\n",
        "        labels (array-like): The labels corresponding to the data. Should be a 1D array-like object.\n",
        "        sample_weights (torch.Tensor): Weights for each sample, inversely proportional to class frequencies.\n",
        "\n",
        "    Methods:\n",
        "        __len__: Returns the number of samples in the dataset.\n",
        "        __getitem__(idx): Returns the sample and its corresponding label at the given index.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "        # Count the number of examples in each class\n",
        "        class_counts = np.bincount(self.labels)\n",
        "        # Assign weight inversely proportional to class frequency\n",
        "        weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "        # Create a weight list for each sample\n",
        "        self.sample_weights = weights[labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "def create_balanced_loader(data, labels, batch_size=32):\n",
        "    \"\"\"\n",
        "    Creates a DataLoader with balanced batches for a given dataset.\n",
        "    This function is useful for training models on imbalanced datasets.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): The input data. Can be a list, NumPy array, or PyTorch tensor.\n",
        "        labels (array-like): The labels corresponding to the data. Should be a 1D array-like object.\n",
        "        batch_size (int, optional): The size of each batch. Default is 32.\n",
        "\n",
        "    Returns:\n",
        "        DataLoader: A PyTorch DataLoader that yields balanced batches.\n",
        "\n",
        "    Usage Example:\n",
        "        >>> data = [features1, features2, ...]  # Replace with your data features\n",
        "        >>> labels = [label1, label2, ...]     # Replace with your data labels\n",
        "        >>> balanced_loader = create_balanced_loader(data, labels, batch_size=32)\n",
        "        >>> for batch_data, batch_labels in balanced_loader:\n",
        "        >>>     # Train your model using the balanced batches\n",
        "    \"\"\"\n",
        "    dataset = BalancedDataset(data, labels)\n",
        "    # WeightedRandomSampler will take care of the balancing\n",
        "    sampler = WeightedRandomSampler(weights=dataset.sample_weights, num_samples=len(dataset.sample_weights), replacement=True)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
        "    return loader\n",
        "\n",
        "\n",
        "class BinaryBalancedSampler(Sampler):\n",
        "    \"\"\"\n",
        "    A PyTorch Sampler that returns batches with an equal number of positive and negative examples.\n",
        "    The sampler oversamples from the minority class to balance the majority class, ensuring that\n",
        "    each batch contains 50% positive and 50% negative examples.\n",
        "\n",
        "    NOTE: It leads to more examples in single iteration through the data loader than in one epoch\n",
        "\n",
        "    Attributes:\n",
        "        class_vector (list or numpy array): class labels.\n",
        "        batch_size (int): The size of each batch.\n",
        "        n_splits (int): The number of batches/splits in the dataset.\n",
        "        equivalent_epochs (float): The number of times the sampler goes over the minority class\n",
        "                                   in one complete iteration of the DataLoader.\n",
        "\n",
        "    Methods:\n",
        "        gen_sample_array: Yields indices for each batch ensuring class balance.\n",
        "        __iter__: Returns an iterator over batch indices.\n",
        "        __len__: Returns the number of batches in the sampler.\n",
        "    \"\"\"\n",
        "    def __init__(self, class_vector, batch_size = 10):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        class_vector : torch tensor\n",
        "            a vector of class labels\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.class_vector = class_vector\n",
        "        YY = np.array(self.class_vector)\n",
        "        U, C = np.unique(YY, return_counts=True)\n",
        "        M = U[np.argmax(C)]        #find majority class\n",
        "        Midx = np.nonzero(YY==M)[0] #indices of majority class\n",
        "        midx = np.nonzero(YY!=M)[0] #indices of minority class\n",
        "        midx_ = np.random.choice(midx,size=len(Midx))     #oversample minority indices so they are equal to majority ones\n",
        "        self.YY = np.array(list(YY[Midx])+list(YY[midx_]))\n",
        "        self.idx = np.array(list(Midx)+list(midx_))\n",
        "        self.n_splits = int(np.ceil(len(self.idx)/self.batch_size))\n",
        "        self.equivalent_epochs = len(self.idx)/len(self.class_vector)\n",
        "        print('Equivalent epochs in one iteration of data loader',self.equivalent_epochs)\n",
        "\n",
        "    def gen_sample_array(self):\n",
        "        from sklearn.model_selection import StratifiedKFold\n",
        "        skf = StratifiedKFold(n_splits= self.n_splits,shuffle=True)\n",
        "        for tridx,ttidx in skf.split(self.idx,self.YY):\n",
        "            yield np.array(self.idx[ttidx])\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.gen_sample_array())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_splits\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    E = [(str(p_i), str(-1*c_i)) for p_i, c_i in zip(range(100), range(100))]  # Replace with your data\n",
        "    Y = np.random.randint(0, 2, size=100)  # Replace with your labels\n",
        "    batch_size = 10\n",
        "\n",
        "    dataset = CustomDataset(E, Y)\n",
        "    batch_sampler = BinaryBalancedSampler(Y, batch_size)\n",
        "    data_loader = DataLoader(dataset, batch_sampler=batch_sampler)\n",
        "\n",
        "    for batch in data_loader:\n",
        "        print(batch)\n",
        "\n",
        "    # Example usage of create_balanced_loader\n",
        "    balanced_loader = create_balanced_loader(E, Y, batch_size)\n",
        "\n",
        "    # Iterate over the DataLoader\n",
        "    L = []\n",
        "    for (pid,cid),label in balanced_loader:\n",
        "        # Process your batches\n",
        "        L.extend(pid)\n",
        "    print(L)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import DataStructs\n",
        "import numpy as np\n",
        "import math\n",
        "from itertools import product\n",
        "from scipy import spatial\n",
        "from os import listdir\n",
        "from Bio import SeqIO\n",
        "from Bio.SeqIO import FastaIO\n",
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "from sklearn.preprocessing import normalize\n",
        "from Bio.Data import IUPACData\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from Bio.PDB import PDBParser\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "from tqdm import tqdm as tqdm\n",
        "# (Assuming PrepairDataset is a custom module you have)\n",
        "# import PrepairDataset\n",
        "\n",
        "def getFP(s, r=3, nBits=2048):\n",
        "    compound = Chem.MolFromSmiles(s.strip())\n",
        "    if compound is not None:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(compound, r, nBits=nBits)\n",
        "        #fp = pat.GetAvalonCountFP(compound,nBits=nBits)\n",
        "        m = np.zeros((0,), dtype=np.int8)\n",
        "        DataStructs.ConvertToNumpyArray(fp, m)\n",
        "        return m\n",
        "\n",
        "def twomerFromSeq(s):\n",
        "    k=2\n",
        "    groups={'A':'1','V':'1','G':'1','I':'2','L':'2','F':'2','P':'2','Y':'3',\n",
        "            'M':'3','T':'3','S':'3','H':'4','N':'4','Q':'4','W':'4',\n",
        "            'R':'5','K':'5','D':'6','E':'6','C':'7'}\n",
        "    crossproduct=[''.join (i) for i in product(\"1234567\",repeat=k)]\n",
        "    for i in range (0,len(crossproduct)): crossproduct[i]=int(crossproduct[i])\n",
        "    ind=[]\n",
        "    for i in range (0,len(crossproduct)): ind.append(i)\n",
        "    combinations=dict(zip(crossproduct,ind))\n",
        "    V=np.zeros(int((math.pow(7,k))))      #defines a vector of 343 length with zero entries\n",
        "    try:\n",
        "        for j in range (0,len(s)-k+1):\n",
        "            kmer=s[j:j+k]\n",
        "            c=''\n",
        "            for l in range(0,k):\n",
        "                c+=groups[kmer[l]]\n",
        "            V[combinations[int(c)]]+=1\n",
        "    except:\n",
        "        count={'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0}\n",
        "        for q in range(0,len(s)):\n",
        "            if s[q]=='A' or s[q]=='V' or s[q]=='G':\n",
        "                count['1']+=1\n",
        "            if s[q]=='I' or s[q]=='L'or s[q]=='F' or s[q]=='P':\n",
        "                count['2']+=1\n",
        "            if s[q]=='Y' or s[q]=='M'or s[q]=='T' or s[q]=='S':\n",
        "                count['3']+=1\n",
        "            if s[q]=='H' or s[q]=='N'or s[q]=='Q' or s[q]=='W':\n",
        "                count['4']+=1\n",
        "            if s[q]=='R' or s[q]=='K':\n",
        "                count['5']+=1\n",
        "            if s[q]=='D' or s[q]=='E':\n",
        "                count['6']+=1\n",
        "            if s[q]=='C':\n",
        "                count['7']+=1\n",
        "        val=list(count.values()  )           #[ 0,0,0,0,0,0,0]\n",
        "        key=list(count.keys()     )           #['1', '2', '3', '4', '5', '6', '7']\n",
        "        m=0\n",
        "        ind=0\n",
        "        for t in range(0,len(val)):     #find maximum value from val\n",
        "            if m<val[t]:\n",
        "                m=val[t]\n",
        "                ind=t\n",
        "        m=key [ind]                     # m=group number of maximum occuring group alphabets in protein\n",
        "        for j in range (0,len(s)-k+1):\n",
        "            kmer=s[j:j+k]\n",
        "            c=''\n",
        "            for l in range(0,k):\n",
        "                if kmer[l] not in groups:\n",
        "                    c+=m\n",
        "                else:\n",
        "                    c+=groups[kmer[l]]\n",
        "            V[combinations[int(c)]]+=1\n",
        "    V=V/(len(s)-1)\n",
        "    return np.array(V)\n",
        "\n",
        "def chainLabel(Cname_T,xl_T,Cname,xl):\n",
        "    \"\"\"\n",
        "    Cname_T: Target chain Name\n",
        "    xl_T: Target chain co-ordinates\n",
        "    Cname: Off Target chain Name\n",
        "    xl: Off Target chain co-ordinates\n",
        "    \"\"\"\n",
        "    tc = getCoords(xl_T)\n",
        "    nc = getCoords(xl)\n",
        "    D = getDist(tc, nc, thr = 8.0)\n",
        "    feats=extract_feats(generate_pair_features(D,xl_T,xl))\n",
        "    return feats\n",
        "\n",
        "def generate_pair_features(dist_info,xl,xr):\n",
        "    prot_dic=make_dic()\n",
        "    #    pdb.set_trace()\n",
        "    for rec in dist_info:\n",
        "        try:\n",
        "            l_letter= three_to_one(xl[rec[0]].get_resname())\n",
        "            r_letter= three_to_one(xr[rec[1]].get_resname())\n",
        "            #            print(l_letter,l_letter)\n",
        "            if (l_letter,r_letter) in prot_dic.keys():\n",
        "                prot_dic[(l_letter,r_letter)]+=1\n",
        "            elif (r_letter,l_letter) in prot_dic.keys():\n",
        "                prot_dic[(r_letter,l_letter)]+=1\n",
        "        except:\n",
        "            prot_dic[('_','_')]+=1\n",
        "    return prot_dic\n",
        "\n",
        "def getCoords(R):\n",
        "    \"\"\"\n",
        "    Get atom coordinates given a list of biopython residues\n",
        "    \"\"\"\n",
        "    Coords = []\n",
        "    for (idx, r) in enumerate(R):\n",
        "        v = [ak.get_coord() for ak in r.get_list()]\n",
        "        Coords.append(v)\n",
        "    return Coords\n",
        "\n",
        "def processProtein(UniqueProtein, PdBloc):#, PdBloc):\n",
        "        data_list = []\n",
        "\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "        device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "        PData_dict={}\n",
        "        for i in range(len(UniqueProtein)):\n",
        "            #print('Converting PDB to Graph: {}/{}'.format(i+1, len(UniqueProtein)))\n",
        "            UniqueProtein[i]=UniqueProtein[i].split('.pdb')[0]\n",
        "            P1=PdBloc+UniqueProtein[i]+'.pdb'\n",
        "            #if P1 in UniqueProtein:\n",
        "            parser = PDBParser()\n",
        "            with warnings.catch_warnings(record=True) as w:\n",
        "              structure = parser.get_structure(\"\", P1)\n",
        "            one_hot_atom=(atom1(structure))\n",
        "\n",
        "            one_hot_res=(res1(structure))\n",
        "            neigh_same_res,neigh_diff_res=(neigh1(structure))\n",
        "            # make the graph ready for PyTorch Geometrics GCN algorithms:\n",
        "            one_hot_atom=torch.tensor(one_hot_atom,dtype=torch.float32).to(device)\n",
        "            one_hot_res=torch.tensor(one_hot_res,dtype=torch.float32).to(device)\n",
        "            neigh_same_res=torch.tensor(neigh_same_res).to(device).long()\n",
        "            neigh_diff_res=torch.tensor(neigh_diff_res).to(device).long()\n",
        "            GNNData = [one_hot_atom,one_hot_res,neigh_same_res,neigh_diff_res]\n",
        "            PData_dict[UniqueProtein[i]]= GNNData\n",
        "        return PData_dict\n",
        "\n",
        "def InterfaceFeatures(Complexs,pdbloc):\n",
        "    Found =  listdir(pdbloc)\n",
        "    InterfaceFeatures=[];InterfaceFeatures=dict(InterfaceFeatures)\n",
        "    comp_id=list(set(Complexs))\n",
        "    for ids in range(len(comp_id)):\n",
        "        if comp_id[ids]+'.pdb' in Found:\n",
        "            stx=pdbloc+'/'+comp_id[ids]+'.pdb'#'/2XA0.pdb'\n",
        "            chains=Struct2chain(stx)\n",
        "            for j in range(len(chains)):\n",
        "                Cname_T,seq_T,L_T,xl_T=chains[j]\n",
        "                for k in range(j,len(chains)):\n",
        "                    Cname,seq,L,xl=chains[k]\n",
        "                    #if Cname_T!=Cname and Cname!=' 'and Cname_T!=' ':\n",
        "                    name=comp_id[ids]#+'_'+Cname_T+'_2_'+Cname\n",
        "                    Interface=chainLabel(Cname_T,xl_T,Cname,xl)\n",
        "                    InterfaceF=np.array(Interface)\n",
        "                    InterfaceF=normalize(np.atleast_2d(InterfaceF), norm='l2', copy=True, axis=1, return_norm=False)\n",
        "                    if name not in InterfaceFeatures.keys():\n",
        "                        InterfaceFeatures[name]=Interface\n",
        "    #pickle.dump(InterfaceFeatures, open(path+Filename+\"_InterfaceFeatures.npy\", \"wb\"))\n",
        "    return InterfaceFeatures\n",
        "\n",
        "def getDist(C0, C1, thr=np.inf):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    N0 = []\n",
        "    N1 = []\n",
        "    for i in range(len(C0)):\n",
        "        for j in range(len(C1)):\n",
        "            d = spatial.distance.cdist(C0[i], C1[j]).min()\n",
        "            # dji=spatial.distance.cdist(C1[j], C0[i]).min()\n",
        "            #d=min(dij,dji)\n",
        "            #print d\n",
        "            if (d < thr):  # and not np.isnan(self.Phi[i]) and not np.isnan(self.Phi[j])\n",
        "                N0.append((i, j, d))\n",
        "                N1.append((j, i, d))\n",
        "    return (N0, N1)\n",
        "\n",
        "def prot_feats_seq(seq):\n",
        "    #Interfacedict=pickle.load(open(path+\"InhibitorNewModel2022/InterfaceFeatures2chainsSVM.npy\",\"rb\"))\n",
        "    #InterfaceF=Interfacedict[complexname]\n",
        "    aa=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
        "    f=[]\n",
        "    X = ProteinAnalysis(str(seq))\n",
        "    X.molecular_weight() #throws an error if 'X' in sequence. we skip such sequences\n",
        "    p=X.get_amino_acids_percent()\n",
        "    dp=[]\n",
        "    for a in aa:\n",
        "        dp.append(p[a])\n",
        "    dp=np.array(dp)\n",
        "    dp=normalize(np.atleast_2d(dp), norm='l2', copy=True, axis=1, return_norm=False)\n",
        "    f.extend(dp[0])\n",
        "    tm=np.array(twomerFromSeq(str(seq)))\n",
        "    tm=normalize(np.atleast_2d(tm), norm='l2', copy=True, axis=1,return_norm=False)\n",
        "    f.extend(tm[0])\n",
        "    return np.array(f)\n",
        "\n",
        "def Struct2chain(stx):\n",
        "    \"\"\"\n",
        "    Seq: sequence of the chain\n",
        "    seq_L:sequence Length\n",
        "    \"\"\"\n",
        "    p = PDBParser()\n",
        "    L=[]\n",
        "    stx=p.get_structure('X',stx)\n",
        "    for model in stx:\n",
        "        for C in model:\n",
        "            RL=[]\n",
        "            for R in C:\n",
        "                RL.append(R)\n",
        "            pp=PPBuilder().build_peptides(C)\n",
        "            if len(pp)==0:\n",
        "                pp=CaPPBuilder().build_peptides(C)\n",
        "            seq=''.join([str(p.get_sequence()) for p in pp])\n",
        "            #seq=''.join([p.get_sequence().tostring() for p in pp])\n",
        "            seq_L=len(seq)\n",
        "            L.append((C.full_id[2],seq,seq_L,RL))\n",
        "    return L\n",
        "\n",
        "def extract_feats(dic):\n",
        "    feats=[]\n",
        "    key_list=np.load('/content/PPI-Inhibitors/Features/'+'prote_letter_pair_keys.npy')#to keep features order same\n",
        "    for key in key_list:\n",
        "        #        pdb.set_trace()\n",
        "        feats.append(dic[(key[0].decode('utf-8'),key[1].decode('utf-8'))])\n",
        "    return feats\n",
        "\n",
        "def make_dic():\n",
        "    prot_dic={}\n",
        "    letters=IUPACData.protein_letters\n",
        "    for i in range(len(letters)):\n",
        "        for j in range(i,len(letters)):\n",
        "            prot_dic[(letters[i],letters[j])]=0.0\n",
        "    prot_dic[('_','_')]=0.0# for Amino acids other than 20 natural\n",
        "    return prot_dic\n",
        "\n",
        "def LoadProtein_SVM_Features(UniqueProtein,Pdbloc):\n",
        "    pdbname=listdir(Pdbloc)\n",
        "    InterfaceFeatures=[];InterfaceFeatures=dict(InterfaceFeatures)\n",
        "    SequenceFeatures=[];SequenceFeatures=dict(SequenceFeatures)\n",
        "    AllFeatures=[];AllFeatures=dict(AllFeatures)\n",
        "    for  b in range(len(UniqueProtein)):\n",
        "        if UniqueProtein[b]+'.pdb'in pdbname:\n",
        "            stx=Pdbloc+UniqueProtein[b]+'.pdb'#directory+'/2XA0.pdb'\n",
        "            chains=Struct2chain(stx)\n",
        "            #########Interface Features\n",
        "            for j in range(len(chains)):\n",
        "                Cname_T,seq_T,L_T,xl_T=chains[j]\n",
        "                for k in range(j,len(chains)):\n",
        "                    Cname,seq,L,xl=chains[k]\n",
        "                    #if Cname_T!=Cname and Cname!=' 'and Cname_T!=' ':\n",
        "                    name=UniqueProtein[b]#+'_'+Cname_T+'_2_'+Cname\n",
        "                    Interface=chainLabel(Cname_T,xl_T,Cname,xl)\n",
        "                    seq_TF=prot_feats_seq(seq_T)\n",
        "                    seq_NTF=prot_feats_seq(seq)\n",
        "                    SeQFeatures=(seq_TF+seq_NTF)/2\n",
        "                    InterfaceF=np.array(Interface)\n",
        "                    InterfaceF=normalize(np.atleast_2d(InterfaceF), norm='l2', copy=True, axis=1, return_norm=False)\n",
        "                    if name not in InterfaceFeatures.keys():\n",
        "                        InterfaceFeatures[name]=Interface\n",
        "                        SequenceFeatures[name]=SeQFeatures\n",
        "                        AllFeatures[name]=np.append(SeQFeatures,Interface)\n",
        "    return InterfaceFeatures,SequenceFeatures,AllFeatures\n",
        "\n",
        "def External_GenerateRandomNegative(posexamples):\n",
        "    NegtiveRatio=1\n",
        "    ###SuperDrugbank###Names\n",
        "    SuperdrugNames=pd.read_excel('/content/PPI-Inhibitors/Data/approved_drugs_chemical_structure_identifiers.xlsx',usecols=\"B\").values#'approved_drugs_chemical_structure_identifiers.xlsx'\n",
        "    SuperdrugNames=SuperdrugNames[1:]\n",
        "    SuperdrugNames = np.array([s[0] for s in SuperdrugNames])\n",
        "    ###############SuperDrugbank\n",
        "    df_Superdrug=pd.read_excel('/content/PPI-Inhibitors/Data/approved_drugs_chemical_structure_identifiers.xlsx',usecols=\"C\").values\n",
        "    df_Superdrug=df_Superdrug[1:]\n",
        "    ###\n",
        "    df_Superdrug_Compounds=np.array([c[0] for c in df_Superdrug])#3638\n",
        "    SuperDrug_dict=dict (zip (SuperdrugNames,df_Superdrug_Compounds))\n",
        "    ################\n",
        "    #path='/content/drive/MyDrive/GNN-PPI-Inhibitor/'\n",
        "    DBD5_ProteinData_dict=pickle.load(open('/content/PPI-Inhibitors/Features/NewUbench5InterfaceandSeq_dict.npy',\"rb\"))\n",
        "    Ubench5CompNames=list (set (list (DBD5_ProteinData_dict.keys())))\n",
        "    ####\n",
        "    AllNeg=[];AllPos=[];complex_ligand_dict={};\n",
        "    for key,val in  posexamples:\n",
        "        #print(key,val,posexamples[key,val][1])\n",
        "        if key not in complex_ligand_dict:\n",
        "            complex_ligand_dict[key]=posexamples[key,val][1]\n",
        "        else:\n",
        "            #print(\"else\",key,val)\n",
        "            complex_ligand_dict[key]=np.append( complex_ligand_dict.get(key, ()) ,posexamples[key,val][1])\n",
        "\n",
        "    Complexnames=list (complex_ligand_dict.keys())\n",
        "    totalcomp=list (set (complex_ligand_dict.keys()))\n",
        "\n",
        "    for everycomp in totalcomp:\n",
        "        origanlL=complex_ligand_dict[everycomp]\n",
        "        #print(origanlL)\n",
        "        #print(\"complexname=\",everycomp,\"origanlInhibitors\",len(origanlL))\n",
        "        pos=[(everycomp,origanlL[t]) for t in range(len(origanlL))]\n",
        "        #print(pos)\n",
        "        NN =NegtiveRatio*len(pos)\n",
        "        negs = []\n",
        "        AllPos.extend(pos)\n",
        "        while (len(negs)<NN):# and len(negs)<(len(totalligands_train)-len(origanlL)):\n",
        "            LigandR = random.choice(SuperdrugNames)\n",
        "            LigandR_smile=SuperDrug_dict[LigandR]\n",
        "            Npair=((everycomp,LigandR_smile))\n",
        "            if LigandR  not in origanlL and Npair not in AllNeg and Npair not in AllPos and getFP(LigandR_smile) is not None:\n",
        "                negs.append(Npair)\n",
        "                #                print(\"Npair SuperdrugNames\",Npair)\n",
        "        AllNeg.extend(negs)\n",
        "\n",
        "    #print(\"N=\",len(AllNeg),\"P\",len(AllPos))\n",
        "    #print(\"second method Cr\")\n",
        "\n",
        "    for everycomp in totalcomp:\n",
        "        origanlL=complex_ligand_dict[everycomp]\n",
        "        #        print(\"everycomp=\",everycomp,\"origanlL\",len(origanlL))\n",
        "        pos=[(everycomp,origanlL[t]) for t in range(len(origanlL))]\n",
        "        NN =NegtiveRatio*len(pos)\n",
        "        negs = []\n",
        "        while (len(negs)<NN):\n",
        "            for everyL in origanlL:\n",
        "                ComplexR = random.choice(Ubench5CompNames)\n",
        "                Npair=((ComplexR,everyL))\n",
        "                if ComplexR!=everycomp and Npair not in AllNeg and Npair not in AllPos:\n",
        "                    #                    print(\"ComplexR,everycomp)\",Npair)\n",
        "                    negs.append(Npair)\n",
        "        AllNeg.extend(negs)\n",
        "    ###################\n",
        "    #print(\"N=\",len(AllNeg),\"P\",len(AllPos))\n",
        "    return np.array(AllPos),np.array(AllNeg),SuperDrug_dict\n",
        "\n",
        "def PredictScorefromFile(filename,Pdbloc,Pscaler,Cscaler,trainedModel_IPPI,train_GNN,LOCOcomplexname):\n",
        "    githubpath='/content/PPI-Inhibitors/'\n",
        "    #filename,Pdbloc,Pscaler,Cscaler,trainedModel_IPPI,train_GNN=githubpath+'Data/External data/2dyh_all.txt',githubpath+'Data/External data/pdb/',Pscaler,Cscaler,IPPI_Net,GNN_model\n",
        "    with open(filename) as f:\n",
        "        D = f.readlines()\n",
        "\n",
        "    InhibitedComp=[];PdbId=[];Ligandnames=[];SMILES=[];targets=[];\n",
        "    All_data_list=[]\n",
        "\n",
        "    #2XA0_A_2_B 2O21 2XA0 43B c1ccc(cc1)CCc2nc3cc(ccc3s2)c4ccc(cc4)C(=O)NS(=O)(=O)c5ccc(c(c5)[N](=O)[O-])NCCSc6ccccc6  1\n",
        "    for d in tqdm(D):\n",
        "        Pdbid,inhibtedc,Ligandid,smiles = d.split()\n",
        "        if getFP(smiles) is not None:\n",
        "            PdbId.append(Pdbid);Ligandnames.append(Ligandid);SMILES.append(smiles);InhibitedComp.append(inhibtedc);#labels.append(float (y));\n",
        "\n",
        "    ################\n",
        "    \"\"\"\n",
        "    Result_dict={}\n",
        "    pos=dict (zip(zip(PdbId, Ligandnames),zip(InhibitedComp,SMILES)))\n",
        "    Pos,Negs,SuperDrug_dict=External_GenerateRandomNegative(pos)\n",
        "    poslabel=1.0*np.ones(len(Pos));neglabel=-1.0*np.ones(len(Negs));targets=np.append(poslabel,neglabel )\n",
        "    All_examples=[];All_examples.extend(Pos);All_examples.extend(Negs)\n",
        "    #Write File for External\n",
        "    External_All_Examples=open('/content/drive/MyDrive/GNN-PPI-Inhibitor/_'+LOCOcomplexname+'_'+filename.split('.txt')[0].split('/')[-1]+'_External_All_Examples.txt',\"w\")\n",
        "    \"\"\"\n",
        "    complexnames=[];SMILES=[];targets=[];\n",
        "    #/content/PPI-Inhibitors/Data/External data/2dyh_all_External_All_Examples.txt\n",
        "    with open('/content/PPI-Inhibitors/Data/External data/'+filename.split('.txt')[0].split('/')[-1]+'_External_All_Examples.txt') as f:\n",
        "        D = f.readlines()\n",
        "\n",
        "    for d in tqdm(D):\n",
        "        complexname,smiles,target= d.split()\n",
        "        complexnames.append(complexname);SMILES.append(smiles);targets.append(target);#All_examples.append()\n",
        "\n",
        "    pdbname=listdir(Pdbloc);mypdb=[]\n",
        "    for p in pdbname:\n",
        "        if p.split('.pdb')[0] in Pdbid:\n",
        "            mypdb.append(p)\n",
        "\n",
        "    UniqueProtein=list (set (mypdb))\n",
        "    External_Protein_GNN_Data_dict=processProtein(UniqueProtein,Pdbloc)\n",
        "\n",
        "    ##########for Seq+interface features\n",
        "    #pdbname=listdir(Pdbloc)\n",
        "    s,i,External_ProteinSeqandInterfaceData_dict=LoadProtein_SVM_Features(UniqueProtein,Pdbloc)\n",
        "\n",
        "    ##############3 for sequence fedatures of DBD5 pdb's\n",
        "    Ubench5InterfaceandSeq_dict=pickle.load(open(githubpath+'Features/NewUbench5InterfaceandSeq_dict.npy',\"rb\"))\n",
        "    All_External_ProteinSeqandInterfaceData_dict=dict( list (External_ProteinSeqandInterfaceData_dict.items())+list (Ubench5InterfaceandSeq_dict.items()))\n",
        "\n",
        "    #Testing\n",
        "    DBD5_Protein_GNN_Data_dict=pickle.load(open(path+'DBD5_ProteinData_dict.pickle',\"rb\"))\n",
        "    #Pos_ProteinData_dict=pickle.load(open(path+'ProteinData_dict.pickle',\"rb\"))\n",
        "    All_Protein_GNN_Data_dict=dict( list (External_Protein_GNN_Data_dict.items())+list (DBD5_Protein_GNN_Data_dict.items()))\n",
        "\n",
        "    for d in All_Protein_GNN_Data_dict:\n",
        "        data=All_Protein_GNN_Data_dict[d]\n",
        "        All_Protein_GNN_Data_dict[d]=[data[0].cuda(),data[1].cuda(),data[2].cuda(),data[3].cuda()]\n",
        "\n",
        "    #####################\n",
        "    Cttname=[];Ctt=[];Pttname=[];Ptt=[];\n",
        "    for (complexname,ligandsmile) in zip(complexnames,SMILES):#All_examples:\n",
        "        Cttname.append(ligandsmile);Ctt.append(getFP(ligandsmile));\n",
        "        Pttname.append(complexname);Ptt.append(All_External_ProteinSeqandInterfaceData_dict[complexname]);\n",
        "\n",
        "    #standarization\n",
        "    Ctt = Cscaler.transform(Ctt)\n",
        "    Cttdict=dict (zip (Cttname,torch.FloatTensor( Ctt).cuda()))\n",
        "    Ptt = Pscaler.transform(Ptt)\n",
        "    Pttdict=dict (zip (Pttname,torch.FloatTensor( Ptt).cuda()))\n",
        "\n",
        "    #########\n",
        "    Y_t,Z,Targets=[],[],[]\n",
        "\n",
        "    # Set models to evaluation mode for inference\n",
        "    trainedModel_IPPI.eval()\n",
        "    train_GNN.eval()\n",
        "\n",
        "    # with torch.no_grad(): # Disable gradient calculations\n",
        "    #     for target,(complexname,ligandsmile) in zip(targets,zip(complexnames,SMILES)):\n",
        "\n",
        "    #         # 1. Get GNN features first by running the GNN model\n",
        "    #         GNN_features = train_GNN(All_Protein_GNN_Data_dict[complexname])\n",
        "\n",
        "    #         # 2. Pass the GNN features (not the model) to the MLP\n",
        "    #         test_score = trainedModel_IPPI(GNN_features, Cttdict[ligandsmile], Pttdict[complexname])\n",
        "\n",
        "    #         test_score=test_score.cpu().data.numpy()[0]\n",
        "    #         Z.append(test_score);Targets.append(float (target))\n",
        "\n",
        "    # return Z,Targets\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculations\n",
        "        for target,(complexname,ligandsmile) in zip(targets,zip(complexnames,SMILES)):\n",
        "\n",
        "            # 1. Get GNN features (already 2D: [1, 512])\n",
        "            GNN_features = train_GNN(All_Protein_GNN_Data_dict[complexname])\n",
        "\n",
        "            # 2. Get Ligand and Interface features (which are 1D)\n",
        "            ligand_feats_1d = Cttdict[ligandsmile]\n",
        "            interface_feats_1d = Pttdict[complexname]\n",
        "\n",
        "            # 3. Add a batch dimension (unsqueeze) to make them 2D\n",
        "            ligand_feats_2d = ligand_feats_1d.unsqueeze(0)       # Shape becomes [1, 2048]\n",
        "            interface_feats_2d = interface_feats_1d.unsqueeze(0)   # Shape becomes [1, 280]\n",
        "\n",
        "            # 4. Pass all 2D tensors to the MLP\n",
        "            test_score = trainedModel_IPPI(GNN_features, ligand_feats_2d, interface_feats_2d)\n",
        "\n",
        "            test_score=test_score.cpu().data.numpy()[0]\n",
        "            Z.append(test_score);Targets.append(float (target))\n",
        "    return Z, Targets"
      ],
      "metadata": {
        "id": "4pYOXb0eXcR1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hn0xj2yWfAYq",
        "outputId": "ad98ed51-95ff-49e3-d3b9-bf85b0758b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Number of GPUs: 1\n",
            "GPU 0: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15695/15695 [00:00<00:00, 791154.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equivalent epochs in one iteration of data loader 1.8249820678348192\n",
            "test complex  2XA0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 11%|█         | 1/9 [00:14<01:53, 14.21s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.3399339933993399 AUCPR 0.0029318476544747656\n",
            "AUCROC 0.3399339933993399 AUCPR 0.0029318476544747656 best aucroc 0.3399339933993399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 22%|██▏       | 2/9 [00:26<01:30, 12.89s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.37190594059405946 AUCPR 0.0030218760415226826\n",
            "AUCROC 0.37190594059405946 AUCPR 0.0030218760415226826 best aucroc 0.37190594059405946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 3/9 [00:39<01:19, 13.28s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.4216171617161716 AUCPR 0.0035885373582438063\n",
            "AUCROC 0.4216171617161716 AUCPR 0.0035885373582438063 best aucroc 0.4216171617161716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 44%|████▍     | 4/9 [00:53<01:06, 13.21s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.47648514851485146 AUCPR 0.00456135511361705\n",
            "AUCROC 0.47648514851485146 AUCPR 0.00456135511361705 best aucroc 0.47648514851485146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 56%|█████▌    | 5/9 [01:06<00:52, 13.19s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.5468234323432343 AUCPR 0.005144042830112822\n",
            "AUCROC 0.5468234323432343 AUCPR 0.005144042830112822 best aucroc 0.5468234323432343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 67%|██████▋   | 6/9 [01:20<00:41, 13.73s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.5992161716171617 AUCPR 0.006010809914538575\n",
            "AUCROC 0.5992161716171617 AUCPR 0.006010809914538575 best aucroc 0.5992161716171617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 78%|███████▊  | 7/9 [01:35<00:27, 13.85s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.6155115511551156 AUCPR 0.005669277822235733\n",
            "AUCROC 0.6155115511551156 AUCPR 0.005669277822235733 best aucroc 0.6155115511551156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 89%|████████▉ | 8/9 [01:49<00:14, 14.03s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.6268564356435643 AUCPR 0.005280299300561922\n",
            "AUCROC 0.6268564356435643 AUCPR 0.005280299300561922 best aucroc 0.6268564356435643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 9/9 [02:02<00:00, 13.58s/it]\n",
            "100%|██████████| 1/1 [02:02<00:00, 122.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTSIDE LOOP AUC of Best\n",
            "Complex name 2XA0 AUCROC 0.6268564356435643 AUCPR 0.005280299300561922\n",
            "\n",
            "External validation for 2XA0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/24 [00:00<?, ?it/s][04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:08] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 24/24 [00:00<00:00, 1570.31it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 564467.08it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2889.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3220.\n",
            "  warnings.warn(\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:14] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Recent Pubs - AUC-ROC: 0.823, AUC-PR: 0.739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/28 [00:00<?, ?it/s][04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:16:15] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] Explicit valence for atom # 0 Cl, 1, is greater than permitted\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:15] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 28/28 [00:00<00:00, 2698.42it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 343952.04it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6961.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7019.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7033.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7104.\n",
            "  warnings.warn(\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:16:28] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  COVID-19 - AUC-ROC: 0.645, AUC-PR: 0.455\n",
            "Equivalent epochs in one iteration of data loader 1.8322724057795292\n",
            "test complex  3WN7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 11%|█         | 1/9 [00:15<02:05, 15.63s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8953843802537064 AUCPR 0.09907512994249205\n",
            "AUCROC 0.8953843802537064 AUCPR 0.09907512994249205 best aucroc 0.8953843802537064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 22%|██▏       | 2/9 [00:32<01:55, 16.50s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.9409292373528964 AUCPR 0.17464470867552745\n",
            "AUCROC 0.9409292373528964 AUCPR 0.17464470867552745 best aucroc 0.9409292373528964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 33%|███▎      | 3/9 [00:48<01:37, 16.23s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.9560599113556473 AUCPR 0.21488585906668564\n",
            "AUCROC 0.9560599113556473 AUCPR 0.21488585906668564 best aucroc 0.9560599113556473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 44%|████▍     | 4/9 [01:02<01:16, 15.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.9659941922665444 AUCPR 0.2550792297461302\n",
            "AUCROC 0.9659941922665444 AUCPR 0.2550792297461302 best aucroc 0.9659941922665444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 56%|█████▌    | 5/9 [01:15<00:57, 14.35s/it]\u001b[A\n",
            " 67%|██████▋   | 6/9 [01:28<00:42, 14.11s/it]\u001b[A\n",
            " 78%|███████▊  | 7/9 [01:43<00:28, 14.44s/it]\u001b[A\n",
            " 89%|████████▉ | 8/9 [01:59<00:14, 14.77s/it]\u001b[A\n",
            "100%|██████████| 9/9 [02:13<00:00, 14.85s/it]\n",
            "100%|██████████| 1/1 [02:13<00:00, 133.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTSIDE LOOP AUC of Best\n",
            "Complex name 3WN7 AUCROC 0.9659941922665444 AUCPR 0.2550792297461302\n",
            "\n",
            "External validation for 3WN7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/24 [00:00<?, ?it/s][04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:45] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 24/24 [00:00<00:00, 1714.47it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 431414.13it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2889.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3220.\n",
            "  warnings.warn(\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:51] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Recent Pubs - AUC-ROC: 0.766, AUC-PR: 0.569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/28 [00:00<?, ?it/s][04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:18:52] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] Explicit valence for atom # 0 Cl, 1, is greater than permitted\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:18:52] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 28/28 [00:00<00:00, 2575.00it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 443450.64it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6961.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7019.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7033.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7104.\n",
            "  warnings.warn(\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:19:05] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  COVID-19 - AUC-ROC: 0.675, AUC-PR: 0.455\n",
            "Equivalent epochs in one iteration of data loader 1.8699573793240163\n",
            "test complex  3UVW\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:22<03:18, 22.04s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8020879060579454 AUCPR 0.34805969749715543\n",
            "AUCROC 0.8020879060579454 AUCPR 0.34805969749715543 best aucroc 0.8020879060579454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 2/10 [00:43<02:53, 21.65s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8173105062920691 AUCPR 0.3696687443812587\n",
            "AUCROC 0.8173105062920691 AUCPR 0.3696687443812587 best aucroc 0.8173105062920691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 30%|███       | 3/10 [01:04<02:31, 21.59s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8221027216856893 AUCPR 0.37843932133923347\n",
            "AUCROC 0.8221027216856893 AUCPR 0.37843932133923347 best aucroc 0.8221027216856893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 40%|████      | 4/10 [01:26<02:08, 21.42s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8275122549019609 AUCPR 0.39162215018615265\n",
            "AUCROC 0.8275122549019609 AUCPR 0.39162215018615265 best aucroc 0.8275122549019609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 50%|█████     | 5/10 [01:47<01:47, 21.47s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8300135352648522 AUCPR 0.4092427458338679\n",
            "AUCROC 0.8300135352648522 AUCPR 0.4092427458338679 best aucroc 0.8300135352648522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 60%|██████    | 6/10 [02:02<01:17, 19.38s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [02:18<00:54, 18.10s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [02:34<00:34, 17.34s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [02:50<00:17, 17.16s/it]\u001b[A\n",
            "100%|██████████| 10/10 [03:06<00:00, 18.67s/it]\n",
            "100%|██████████| 1/1 [03:06<00:00, 186.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTSIDE LOOP AUC of Best\n",
            "Complex name 3UVW AUCROC 0.8300135352648522 AUCPR 0.4092427458338679\n",
            "\n",
            "External validation for 3UVW...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/24 [00:00<?, ?it/s][04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:14] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 24/24 [00:00<00:00, 1672.43it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 442152.11it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2889.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3220.\n",
            "  warnings.warn(\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:21] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:22] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:22] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:22] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:22] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:22] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:22] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Recent Pubs - AUC-ROC: 0.725, AUC-PR: 0.715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/28 [00:00<?, ?it/s][04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:22:23] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] Explicit valence for atom # 0 Cl, 1, is greater than permitted\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:23] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 28/28 [00:00<00:00, 2480.32it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 531672.34it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6961.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7019.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7033.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7104.\n",
            "  warnings.warn(\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:22:36] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  COVID-19 - AUC-ROC: 0.532, AUC-PR: 0.433\n",
            "Equivalent epochs in one iteration of data loader 1.8404592240696753\n",
            "test complex  1YCR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:15<02:23, 15.99s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.7963301428502718 AUCPR 0.09152859866893631\n",
            "AUCROC 0.7963301428502718 AUCPR 0.09152859866893631 best aucroc 0.7963301428502718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 2/10 [00:34<02:18, 17.29s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8196094463950747 AUCPR 0.11235699064592039\n",
            "AUCROC 0.8196094463950747 AUCPR 0.11235699064592039 best aucroc 0.8196094463950747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 30%|███       | 3/10 [00:51<02:02, 17.48s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8383194651531912 AUCPR 0.1360751530181597\n",
            "AUCROC 0.8383194651531912 AUCPR 0.1360751530181597 best aucroc 0.8383194651531912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 40%|████      | 4/10 [01:06<01:39, 16.51s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [01:21<01:18, 15.67s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [01:35<01:00, 15.08s/it]\u001b[A\n",
            " 70%|███████   | 7/10 [01:49<00:44, 14.92s/it]\u001b[A\n",
            " 80%|████████  | 8/10 [02:04<00:29, 14.83s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [02:19<00:14, 14.97s/it]\u001b[A\n",
            "100%|██████████| 10/10 [02:33<00:00, 15.36s/it]\n",
            "100%|██████████| 1/1 [02:33<00:00, 153.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUTSIDE LOOP AUC of Best\n",
            "Complex name 1YCR AUCROC 0.8383194651531912 AUCPR 0.1360751530181597\n",
            "\n",
            "External validation for 1YCR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/24 [00:00<?, ?it/s][04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:13] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 24/24 [00:00<00:00, 1593.76it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 474826.87it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 2889.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 3220.\n",
            "  warnings.warn(\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:18] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Recent Pubs - AUC-ROC: 0.866, AUC-PR: 0.780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/28 [00:00<?, ?it/s][04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:25:20] Can't kekulize mol.  Unkekulized atoms: 5 6 7 8 9 10 11 12 13\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] Explicit valence for atom # 0 Cl, 1, is greater than permitted\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:20] DEPRECATION WARNING: please use MorganGenerator\n",
            "100%|██████████| 28/28 [00:00<00:00, 2880.14it/s]\n",
            "100%|██████████| 72/72 [00:00<00:00, 490243.32it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 6961.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7019.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7033.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/Bio/PDB/StructureBuilder.py:89: PDBConstructionWarning: WARNING: Chain E is discontinuous at line 7104.\n",
            "  warnings.warn(\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n",
            "[04:25:32] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  COVID-19 - AUC-ROC: 0.683, AUC-PR: 0.506\n",
            "Equivalent epochs in one iteration of data loader 1.8627039839547817\n",
            "test complex  4QC3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:19<02:51, 19.04s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8727616645649433 AUCPR 0.6353973554479312\n",
            "AUCROC 0.8727616645649433 AUCPR 0.6353973554479312 best aucroc 0.8727616645649433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 20%|██        | 2/10 [00:38<02:34, 19.30s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8885245901639345 AUCPR 0.679714926540275\n",
            "AUCROC 0.8885245901639345 AUCPR 0.679714926540275 best aucroc 0.8885245901639345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 30%|███       | 3/10 [00:54<02:04, 17.73s/it]\u001b[A\n",
            " 40%|████      | 4/10 [01:09<01:39, 16.59s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [01:27<01:26, 17.32s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8916771752837326 AUCPR 0.6950675273738505\n",
            "AUCROC 0.8916771752837326 AUCPR 0.6950675273738505 best aucroc 0.8916771752837326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 60%|██████    | 6/10 [01:47<01:12, 18.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.8996216897856242 AUCPR 0.7020720321800702\n",
            "AUCROC 0.8996216897856242 AUCPR 0.7020720321800702 best aucroc 0.8996216897856242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 70%|███████   | 7/10 [02:06<00:55, 18.40s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.907124842370744 AUCPR 0.7048321387259263\n",
            "AUCROC 0.907124842370744 AUCPR 0.7048321387259263 best aucroc 0.907124842370744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " 80%|████████  | 8/10 [02:26<00:37, 18.87s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADED BEST AUCROC 0.9128625472887768 AUCPR 0.7283571344816856\n",
            "AUCROC 0.9128625472887768 AUCPR 0.7283571344816856 best aucroc 0.9128625472887768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [02:38<00:39, 19.82s/it]\n",
            "  0%|          | 0/1 [02:38<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3960031682.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m#if np.median(Loss[-10:])<1e-1: terminated = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mearly_stop_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Jan  9 13:06:21 2024\n",
        "\n",
        "@author: u1876024\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "from Bio.PDB import *\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import glob\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import pdb\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import glob\n",
        "from Bio.PDB import *\n",
        "import warnings\n",
        "from Bio.PDB import *\n",
        "import numpy as np\n",
        "from Bio.PDB.NeighborSearch import NeighborSearch\n",
        "from tqdm import tqdm as tqdm\n",
        "import pickle\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.metrics import auc,precision_recall_curve\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score,roc_curve,precision_score,recall_score,average_precision_score\n",
        "import pickle\n",
        "from rdkit import Chem\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "from torch.autograd import Variable\n",
        "def cuda(v):\n",
        "    if USE_CUDA:\n",
        "        return v.cuda()\n",
        "    return v\n",
        "def toTensor(v,dtype = torch.float,requires_grad = False):\n",
        "    return cuda(Variable(torch.tensor(v)).type(dtype).requires_grad_(requires_grad))\n",
        "def toNumpy(v):\n",
        "    if USE_CUDA:\n",
        "        return v.detach().cpu().numpy()\n",
        "    return v.detach().numpy()\n",
        "\n",
        "'''\n",
        "Using Sklearn One hot encoder to encode the atoms\n",
        "Output is of size N*M where N is the total number of atoms and M is the total number of encoded features\n",
        "'''\n",
        "def atom1(structure):\n",
        "    atomslist=np.array(sorted(np.array(['C', 'CA', 'CB', 'CG', 'CH2', 'N','NH2',  'OG','OH', 'O1', 'O2', 'SE','1']))).reshape(-1,1)\n",
        "    enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc.fit(atomslist)\n",
        "    atom_list=[]\n",
        "    for atom in structure.get_atoms():\n",
        "        if atom.get_name() in atomslist:\n",
        "            atom_list.append(atom.get_name())\n",
        "        else:\n",
        "            atom_list.append(\"1\")\n",
        "    atoms_onehot=enc.transform(np.array(atom_list).reshape(-1,1)).toarray()\n",
        "    return atoms_onehot\n",
        "##############\n",
        "'''\n",
        "One hot encoded residue infomration using SKlearn Library\n",
        "\n",
        "Output is N*M where N is the total number of atoms and M is the encoded features of the residues.\n",
        "Any unknown  residue is mapped to 1\n",
        "'''\n",
        "\n",
        "\n",
        "def res1(structure):\n",
        "    residuelist=np.array(sorted(np.array(['ALA', 'ARG', 'ASN', 'ASP', 'GLN', 'GLU', 'GLY', 'ILE', 'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'CYS', 'HIS','1']))).reshape(-1,1)\n",
        "    encr = OneHotEncoder(handle_unknown='ignore')\n",
        "    encr.fit(residuelist)\n",
        "    residue_list=[]\n",
        "    for atom in structure.get_atoms():\n",
        "        if atom.get_parent().get_resname() in residuelist:\n",
        "            residue_list.append((atom.get_parent()).get_resname())\n",
        "        else:\n",
        "            residue_list.append(\"1\")\n",
        "\n",
        "    res_onehot=encr.transform(np.array(residue_list).reshape(-1,1)).toarray()\n",
        "\n",
        "    return res_onehot\n",
        "###########\n",
        "\n",
        "'''\n",
        "It calculates the neighbours of each atom i.e. 10 distinct neighbours\n",
        "Output is  in the form of a ditionary representing an  adjacency list where each source atom and neighbouring atom is represented bby its sequence index .\n",
        "'''\n",
        "\n",
        "\n",
        "def neigh1(structure):\n",
        "    #atom_list is a numpy array  that   contains all the atoms of the pdb file in atom object\n",
        "    atom_list=np.array([atom for atom in structure.get_atoms()])\n",
        "\n",
        "    #for atom in structure.get_atoms():\n",
        "    #    atom_list.append(atom)\n",
        "    #neighbour_list contains all the  neighbour atomic pairs  i.e. like if N has neighbours O and C then it is stored as [[N,C],[N,O]] i.e. has dimension N*2 where N is the total number of possible neighbours all the atoms have in an unsorted manner and it stores in the form of  atom object\n",
        "\n",
        "\n",
        "    p4=NeighborSearch(atom_list)\n",
        "    neighbour_list=p4.search_all(6,level=\"A\")\n",
        "    neighbour_list=np.array(neighbour_list)\n",
        "\n",
        "    #dist is the distance between the neighbour and the source atom  i.e. dimension is N*1\n",
        "    dist=np.array(neighbour_list[:,0]-neighbour_list[:,1])\n",
        "    #sorting in ascending order\n",
        "    place=np.argsort(dist)\n",
        "    sorted_neighbour_list=neighbour_list[place]\n",
        "\n",
        "    #old_atom_number is used for  storing atom id of the original protein before sorting\n",
        "    #old_residue_number is used for storing residue number of the original protein before sorting\n",
        "    source_vertex_list_atom_object=np.array(sorted_neighbour_list[:,0])\n",
        "    len_source_vertex=len(source_vertex_list_atom_object)\n",
        "    neighbour_vertex_with_respect_each_source_atom_object=np.array(sorted_neighbour_list[:,1])\n",
        "    old_atom_number=[]\n",
        "    old_residue_number=[]\n",
        "    for i in atom_list:\n",
        "        old_atom_number.append(i.get_serial_number())\n",
        "        old_residue_number.append(i.get_parent().get_id()[1])\n",
        "    old_atom_number=np.array(old_atom_number)\n",
        "    old_residue_number=np.array(old_residue_number)\n",
        "    req_no=len(neighbour_list)\n",
        "    total_atoms=len(atom_list)\n",
        "    #neigh_same_res is the 2D numpy array to store the indices of the  neighbours of  same residue and is of the shape N*10 where N is the total number of atoms\n",
        "    #neigh_diff_res is 2D numpy array to store  the indices of the  neighbours of different residue\n",
        "    #same_flag is used to restrict the neighbours belonging to same residue  to 10\n",
        "    #diff_flag is used to restrict the neighbours belonging to different residue to 10\n",
        "    neigh_same_res=np.array([[-1]*10 for i in range(total_atoms)])\n",
        "    neigh_diff_res=np.array([[-1]*10 for i in range(total_atoms)])\n",
        "    same_flag=[0]*total_atoms\n",
        "    diff_flag=[0]*total_atoms\n",
        "    for i in range(len_source_vertex):\n",
        "        source_atom_id=source_vertex_list_atom_object[i].get_serial_number()\n",
        "        neigh_atom_id=neighbour_vertex_with_respect_each_source_atom_object[i].get_serial_number()\n",
        "        source_atom_res=source_vertex_list_atom_object[i].get_parent().get_id()[1]\n",
        "        neigh_atom_res=neighbour_vertex_with_respect_each_source_atom_object[i].get_parent().get_id()[1]\n",
        "        #finding out index of the source and neighbouring atoms from the original atom array with respect to their residue id and atom id\n",
        "        temp_index1=np.where(source_atom_id==old_atom_number)[0]\n",
        "\n",
        "        temp_index2=np.where(neigh_atom_id==old_atom_number)[0]\n",
        "        for i1 in temp_index1:\n",
        "            if old_residue_number[i1]==source_atom_res:\n",
        "                source_index=i1\n",
        "                break\n",
        "        for i1 in temp_index2:\n",
        "            if old_residue_number[i1]==neigh_atom_res:\n",
        "                neigh_index=i1\n",
        "                break\n",
        "        #if both the residues are same\n",
        "\n",
        "        if source_atom_res==neigh_atom_res :\n",
        "\n",
        "            #limiting the number of neighbours of same residue to 10\n",
        "\n",
        "            if int(same_flag[source_index])< 10:\n",
        "                neigh_same_res[source_index][same_flag[source_index]]=neigh_index\n",
        "                same_flag[source_index]+=1\n",
        "\n",
        "            if int(same_flag[neigh_index])< 10:\n",
        "                neigh_same_res[neigh_index][same_flag[neigh_index]]=source_index\n",
        "                same_flag[neigh_index]+=1\n",
        "\n",
        "        # if both the residues are different\n",
        "        elif source_atom_res!=neigh_atom_res :\n",
        "\n",
        "            #limiting the number of neighbours of different residues to 10\n",
        "\n",
        "            if int(diff_flag[source_index])< 10:\n",
        "                neigh_diff_res[source_index][diff_flag[source_index]]=neigh_index\n",
        "                diff_flag[source_index]+=1\n",
        "\n",
        "\n",
        "            if int(diff_flag[neigh_index])< 10:\n",
        "\n",
        "                neigh_diff_res[neigh_index][diff_flag[neigh_index]]=source_index\n",
        "                diff_flag[neigh_index]+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return neigh_same_res,neigh_diff_res\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available. Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")\n",
        "class GNN_Layer(nn.Module):\n",
        "\n",
        "    def __init__(self, filters, v_feats, trainable=True, **kwargs):\n",
        "        #pdb.set_trace()\n",
        "        super(GNN_Layer, self).__init__()\n",
        "        self.v_feats = v_feats\n",
        "        self.filters = filters\n",
        "\n",
        "        self.trainable = trainable\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "        device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "        self.cuda_device=device\n",
        "        self.Wsv = nn.Parameter( torch.randn(self.v_feats, self.filters, device=self.cuda_device,requires_grad=True))\n",
        "        self.Wdr = nn.Parameter( torch.randn(self.v_feats, self.filters, device=self.cuda_device,requires_grad=True))\n",
        "        self.Wsr = nn.Parameter( torch.randn(self.v_feats, self.filters, device=self.cuda_device,requires_grad=True))\n",
        "        self.neighbours=10\n",
        "        #print(\"Wsv shape\",self.Wsv.shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #pdb.set_trace()\n",
        "        Z,same_neigh,diff_neigh = x\n",
        "        node_signals = Z@self.Wsv\n",
        "        neigh_signals_same=Z@self.Wsr\n",
        "        neigh_signals_diff=Z@self.Wdr\n",
        "        unsqueezed_same_neigh_indicator=(same_neigh>-1).unsqueeze(2)\n",
        "        unsqueezed_diff_neigh_indicator=(diff_neigh>-1).unsqueeze(2)\n",
        "        same_neigh_features=neigh_signals_same[same_neigh]*unsqueezed_same_neigh_indicator\n",
        "        diff_neigh_features=neigh_signals_diff[diff_neigh]*unsqueezed_diff_neigh_indicator\n",
        "        same_norm = torch.sum(same_neigh > -1, 1).unsqueeze(1).type(torch.float)\n",
        "        diff_norm = torch.sum(diff_neigh > -1, 1).unsqueeze(1).type(torch.float)\n",
        "\n",
        "        # To prevent divide by zero error\n",
        "        same_norm[same_norm==0]=1\n",
        "        diff_norm[diff_norm==0]=1\n",
        "        neigh_same_atoms_signal = (torch.sum(same_neigh_features, axis=1))/same_norm\n",
        "        neigh_diff_atoms_signal = (torch.sum(diff_neigh_features, axis=1))/diff_norm\n",
        "        final_res = torch.relu(node_signals +neigh_same_atoms_signal+neigh_diff_atoms_signal)\n",
        "\n",
        "        return final_res,same_neigh,diff_neigh\n",
        "\n",
        "class GNN_First_Layer(nn.Module):\n",
        "\n",
        "    def __init__(self, filters, trainable=True, **kwargs):\n",
        "\n",
        "        super(GNN_First_Layer, self).__init__()\n",
        "        self.filters = filters\n",
        "        #pdb.set_trace()\n",
        "        self.trainable = trainable\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "        device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "        self.cuda_device = device\n",
        "        self.Wv = nn.Parameter( torch.randn(13, self.filters, device=self.cuda_device,requires_grad=True))\n",
        "        self.Wr = nn.Parameter( torch.randn(21,self.filters, device=self.cuda_device,requires_grad=True))\n",
        "        self.Wsr= nn.Parameter( torch.randn(13, self.filters, device=self.cuda_device,requires_grad=True))\n",
        "        self.Wdr= nn.Parameter( torch.randn(13, self.filters, device=self.cuda_device,requires_grad=True))\n",
        "        self.neighbours=10\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        atoms, residues,same_neigh,diff_neigh = x\n",
        "        node_signals = atoms@self.Wv\n",
        "        residue_signals = residues@self.Wr\n",
        "        neigh_signals_same=atoms@self.Wsr\n",
        "        neigh_signals_diff=atoms@self.Wdr\n",
        "        unsqueezed_same_neigh_indicator=(same_neigh>-1).unsqueeze(2)\n",
        "        unsqueezed_diff_neigh_indicator=(diff_neigh>-1).unsqueeze(2)\n",
        "        \"\"\"\n",
        "        unsqueezed_same_neigh_indicator=(same_neigh>-1).unsqueeze(1)\n",
        "        unsqueezed_diff_neigh_indicator=(diff_neigh>-1).unsqueeze(1)\n",
        "        \"\"\"\n",
        "        same_neigh_features=neigh_signals_same[same_neigh]*unsqueezed_same_neigh_indicator\n",
        "        diff_neigh_features=neigh_signals_diff[diff_neigh]*unsqueezed_diff_neigh_indicator\n",
        "        #print(\"same norm\",same_neigh > -1, 1)\n",
        "        same_norm = torch.sum(same_neigh > -1, 1).unsqueeze(1).type(torch.float)\n",
        "        diff_norm = torch.sum(diff_neigh > -1, 1).unsqueeze(1).type(torch.float)\n",
        "        same_norm = torch.sum(same_neigh > -1).type(torch.float)\n",
        "        diff_norm = torch.sum(diff_neigh > -1).type(torch.float)\n",
        "        # To prevent divide by zero error\n",
        "        same_norm[same_norm==0]=1\n",
        "        diff_norm[diff_norm==0]=1\n",
        "        neigh_same_atoms_signal=(torch.sum(same_neigh_features, axis=1))/same_norm\n",
        "        neigh_diff_atoms_signal=(torch.sum(diff_neigh_features, axis=1))/diff_norm\n",
        "\n",
        "        final_res = torch.relu(node_signals+residue_signals +neigh_same_atoms_signal+neigh_diff_atoms_signal)\n",
        "\n",
        "        return final_res, same_neigh,diff_neigh\n",
        "\n",
        "\n",
        "class Dense(nn.Module):\n",
        "    def __init__(self, in_dims, out_dims, trainable=True, **kwargs):\n",
        "        #pdb.set_trace()\n",
        "        super(Dense, self).__init__()\n",
        "        self.in_dims = in_dims\n",
        "        self.out_dims = out_dims\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "        device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "        self.cuda_device = device\n",
        "\n",
        "        self.W = nn.Parameter( torch.randn(self.in_dims, self.out_dims, device=self.cuda_device,requires_grad=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        #pdb.set_trace()\n",
        "        Z = torch.sigmoid(torch.matmul(x, self.W))\n",
        "\n",
        "        return Z\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GNN_First_Layer(filters=512)\n",
        "        self.conv2 = GNN_Layer(v_feats=512, filters=1024)\n",
        "        self.conv3 = GNN_Layer(v_feats=1024, filters=512)\n",
        "        self.dense = Dense(in_dims=512, out_dims=1)\n",
        "    def forward(self, x):\n",
        "        x1=self.conv1(x)\n",
        "        x2=self.conv2(x1)\n",
        "        x3=self.conv3(x2)\n",
        "        x=x3[0]\n",
        "        x=torch.sum(x,axis=0).view(1,-1)\n",
        "        x = F.normalize(x)\n",
        "        return x\n",
        "\n",
        "def readFile(filename):\n",
        "  with open(filename) as f:\n",
        "    D = f.readlines()\n",
        "  Name=[];PdbId=[];Ligandnames=[];SMILES=[];labels=[];\n",
        "  All_data_list=[]\n",
        "  from tqdm import tqdm as tqdm\n",
        "  #2XA0_A_2_B 2O21 2XA0 43B c1ccc(cc1)CCc2nc3cc(ccc3s2)c4ccc(cc4)C(=O)NS(=O)(=O)c5ccc(c(c5)[N](=O)[O-])NCCSc6ccccc6  1\n",
        "  for d in tqdm(D):\n",
        "      #if len(d)==6:\n",
        "      name,inhibtedc,Pdbid,Ligandid,smiles,y = d.split()\n",
        "      Name.append(name);PdbId.append(Pdbid);Ligandnames.append(Ligandid);SMILES.append(smiles);labels.append(float (y));\n",
        "  return  PdbId,Ligandnames,SMILES,labels\n",
        "class IPPI_MLP_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IPPI_MLP_Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2840, 1024)#4096)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 100)\n",
        "        self.fc6 = nn.Linear(100, 1)\n",
        "    def forward(self, PFeatures,LigandFeatures,ProteinInterfaceF):\n",
        "          Cfeatures=LigandFeatures\n",
        "          P_all_Features=torch.hstack((PFeatures,ProteinInterfaceF))\n",
        "          PC_Features=torch.hstack((P_all_Features,Cfeatures))\n",
        "          x = torch.tanh(self.fc1(PC_Features))\n",
        "          x = torch.tanh(self.fc2(x))\n",
        "          x = torch.relu(self.fc3(x))\n",
        "          x = self.fc6(x)\n",
        "          return x\n",
        "\n",
        "#path,githubpath='/content/drive/MyDrive/GNN-PPI-Inhibitor/','/content/PPI-Inhibitors/'\n",
        "path,githubpath='/content/drive/MyDrive/GNN-PPI-Inhibitor/','/content/PPI-Inhibitors/'\n",
        "\"\"\"\n",
        "path = location of pkl files from these links:\n",
        "https://drive.google.com/file/d/1goeDiPZSKT1Xx3j00eNG9xlqYkLLv1gW/view\n",
        "https://drive.google.com/file/d/1GOYEKLQCoGea9QQ72kujy0rdJKbUSYAE/view\n",
        "\n",
        "githubpath =  location of the directory containing the github repo PPI-Inhibitors\n",
        "obtained using\n",
        "git clone https://github.com/adibayaseen/PPI-Inhibitors\n",
        "\"\"\"\n",
        "Ubench5InterfaceandSeq_dict=pickle.load(open(githubpath+'Features/NewUbench5InterfaceandSeq_dict.npy',\"rb\"))\n",
        "Pos_seqandInterfaceF_dict=pickle.load(open(githubpath+'Features/Pos_seqandInterfaceF_dict.npy',\"rb\"))\n",
        "Complex_AllFeatures_dict=dict( list (Pos_seqandInterfaceF_dict.items())+list (Ubench5InterfaceandSeq_dict.items()))\n",
        "##############\n",
        "ComplexInterfaceFeatures={}\n",
        "for key in Complex_AllFeatures_dict:\n",
        "  if len(key.split('_'))>1:\n",
        "    compname=key.split('_')[0]\n",
        "    ComplexInterfaceFeatures[compname]=Complex_AllFeatures_dict[key]#.cuda()\n",
        "  else:\n",
        "    ComplexInterfaceFeatures[key]=Complex_AllFeatures_dict[key]#.cuda()\n",
        "CompoundFingerprintFeaturesDict=pickle.load(open(githubpath+'Features/Compound_Fingerprint_Features_Dict.npy',\"rb\"))\n",
        "#Load Protein data for GNN\n",
        "path='/content/drive/MyDrive/GNN-PPI-Inhibitor/'\n",
        "ProteinDataGNN_dict=pickle.load(open(path+'ProteinData_dict.pickle',\"rb\"))\n",
        "DBD5_ProteinDataGNN_dict=pickle.load(open(path+'DBD5_ProteinData_dict.pickle',\"rb\"))\n",
        "All_ProteinData_dict=dict( list (ProteinDataGNN_dict.items())+list (DBD5_ProteinDataGNN_dict.items()))\n",
        "for d in All_ProteinData_dict:\n",
        "  data=All_ProteinData_dict[d]\n",
        "  All_ProteinData_dict[d]=[data[0].cuda(),data[1].cuda(),data[2].cuda(),data[3].cuda()]\n",
        "#########\n",
        "with open(githubpath+'Data/WriteAllexamplesRandomBindersIdsAll_24JAN_Binary.txt') as f:\n",
        "#with open(githubpath+'Data/WriteAllexamplesRandomBindersIdsAll_24JAN.txt') as f:\n",
        "    D = f.readlines()\n",
        "\n",
        "    # --- ADD THIS BLOCK TO CREATE A SAMPLE ---\n",
        "    ##Smaller samples########\n",
        "    D_all = f.readlines() # Renamed to D_all\n",
        "    sample_size = 100 # <-- Set your desired sample size here\n",
        "    D = random.sample(D_all, min(sample_size, len(D_all)))\n",
        "    print(f\"--- ⚠️  RUNNING ON A SMALL SAMPLE OF {len(D)} EXAMPLES ---\")\n",
        "    # ------------------------------------------\n",
        "Labels=[];Ligandnames=[];Complexs=[];TestPoscomplexes=[];#SMILESlist=[];\n",
        "for d in tqdm(D):\n",
        "  if len(d.split())==4:\n",
        "      TestPoscomp,Complexname,Ligandname,label = d.split()\n",
        "  else:\n",
        "      TestPoscomp,Complexname,Ligandname,label = d.split()[0],d.split()[1],(' ').join(d.split()[2:-1]),d.split()[-1]\n",
        "  TestPoscomplexes.append(TestPoscomp),Ligandnames.append(Ligandname);Complexs.append(Complexname);Labels.append(float (label))\n",
        "#########Make dictionary, Rootcomplexname=(complexname,compoundname),label\n",
        "Allexamples=dict (zip(zip(TestPoscomplexes,zip(Complexs,Ligandnames)),Labels))\n",
        "#Group kfold\n",
        "Alldata=list (Allexamples.keys())\n",
        "KK=[k[0].split('_')[0] for k in Alldata]\n",
        "groups = pd.DataFrame(KK)\n",
        "gkf = GroupKFold(n_splits=len(set (KK)))\n",
        "###########\n",
        "AUC_ROC_final=[];Avg_P_final=[];Z=[];Yo=[];Y_t=[];Y_score=[];\n",
        "from os import listdir\n",
        "AlltestExamples=[];Externallabels=[];ExternalscoresLOCO=[];covid19_Externallabels=[];covid19_ExternalscoresLOCO=[];Y_score=[];Y_t=[];classratio_dict={};\n",
        "AUC_ROC_final=[];Avg_P_final=[];\n",
        "Complexs,Ligandnames, Labels=np.array(Complexs),np.array(Ligandnames),np.array(Labels)\n",
        "Alldata=np.array(Alldata, dtype=object)\n",
        "classratio_dict=pickle.load(open(githubpath+'Features/Classratio_GNNdict.npy','rb'))\n",
        "\n",
        "#%% Cross-validation\n",
        "# Done=set(KK).difference(['3D9T','1BKD','4ESG','2FLU','1YCQ','2XA0','3TDU','3D9T','2B4J','3DAB','3UVW','2RNY','4AJY', '1F47','1YCR','4QC3','1NW9','2E3K','4YY6','4GQ6','3WN7','1BXL','1Z92'])\n",
        "Done={'3D9T','1BKD'}\n",
        "for trainindex, testindex in gkf.split(KK, KK, groups=groups):\n",
        "    train,test=Alldata[trainindex],Alldata[testindex]\n",
        "    test_complex_name = test[0][0].split('_')[0]\n",
        "\n",
        "    # if test[0][0].split('_')[0] in Done:\n",
        "    if test_complex_name not in Done:\n",
        "      continue\n",
        "\n",
        "    Ctr=[];Ptr=[];y_train=[];Ctrname=[];Ptrname=[];Xtr=[];G=[];Cttname=[];Ctt=[];y_test=[];Ptt=[];Pttname=[];\n",
        "    #Split train and test\n",
        "    for t in train:\n",
        "        Ctrname.append(t[1][1]);Ctr.append(CompoundFingerprintFeaturesDict[t[1][1]]);\n",
        "        #change this only for GNN Complex_AllFeatures_dict with All_ProteinData_dic and t\n",
        "        #####\n",
        "        GNNcomp=t[1][0].split('_')[0]#t[1][0].split('_')[0]\n",
        "        Ptrname.append(GNNcomp);Ptr.append(ComplexInterfaceFeatures[GNNcomp]);\n",
        "        y_train.append(Allexamples[t[0],t[1]])\n",
        "    #Split train and test\n",
        "    for t in test:\n",
        "        GNNcomp=t[1][0].split('_')[0]\n",
        "        Cttname.append(t[1][1]);Ctt.append(CompoundFingerprintFeaturesDict[t[1][1]]);\n",
        "        Pttname.append(GNNcomp);Ptt.append(ComplexInterfaceFeatures[GNNcomp]);\n",
        "        y_test.append(Allexamples[t[0],t[1]])\n",
        "    #standarization\n",
        "    Pscaler = StandardScaler().fit(Ptr)\n",
        "    Cscaler = StandardScaler().fit(Ctr)\n",
        "    Ctr = Cscaler.transform(Ctr)\n",
        "    Ptr=Pscaler.transform(Ptr)\n",
        "    Ptt=Pscaler.transform(Ptt)\n",
        "    Ptrdict=dict (zip(Ptrname,torch.FloatTensor(Ptr).cuda()))\n",
        "    Ctrdict=dict (zip (Ctrname,torch.FloatTensor( Ctr).cuda()))\n",
        "    Ctt = Cscaler.transform(Ctt)\n",
        "    Cttdict=dict (zip (Cttname,torch.FloatTensor( Ctt).cuda()))\n",
        "    Pttdict=dict (zip(Pttname,torch.FloatTensor(Ptt).cuda()))\n",
        "\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    IPPI_Net = IPPI_MLP_Net().cuda()\n",
        "\n",
        "    GNN_model=GNN().cuda()\n",
        "    Mcomplexname=test[0][0].split('_')[0]\n",
        "    criterion  = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(list (IPPI_Net.parameters()) + list( GNN_model.parameters()),lr=0.001,weight_decay=0.0)#001)#0.69 for 1mer single layer#, weight_decay=0.01, betas=(0.9, 0.999))\n",
        "\n",
        "    # bsize = 1024\n",
        "    bsize = 2048\n",
        "\n",
        "\n",
        "    dataset = CustomDataset(train[:,1], y_train.astype('int'))\n",
        "    batch_sampler = BinaryBalancedSampler(y_train.astype('int'), bsize)\n",
        "    loader = DataLoader(dataset, batch_sampler=batch_sampler) # data loader that selects equal number of positive and negative examples\n",
        "\n",
        "    test_dataset = CustomDataset(test[:,1], np.array(y_test).astype('int'))\n",
        "    test_loader = DataLoader(test_dataset, batch_size=bsize, shuffle=False)\n",
        "\n",
        "\n",
        "    #y_train=torch.FloatTensor( y_train).cuda()\n",
        "    ####\n",
        "    print (\"test complex \", Mcomplexname)\n",
        "\n",
        "    Loss = [] #save loss values for plotting\n",
        "    E = [] #save examples\n",
        "    L = [] #save labels\n",
        "    terminated = False\n",
        "    best_result = 0.0\n",
        "    best_model = None\n",
        "    counter = 0\n",
        "    early_stop_count = 0\n",
        "    Zlist,Ylist=[],[]\n",
        "    NUM_EPOCHS = 1\n",
        "    for iters in tqdm(range(NUM_EPOCHS)):\n",
        "        for (batch_pids,batch_cids),batch_labels in tqdm(loader):\n",
        "            GNN_model.train()\n",
        "            IPPI_Net.train()\n",
        "            E.extend(zip(batch_pids,batch_cids))\n",
        "            L.append(batch_labels)\n",
        "            pids = [p.split('_')[0] for p in batch_pids]\n",
        "            G_dict = {p:GNN_model(All_ProteinData_dict[p]) for p in set(pids)} #pass each unique complex through the GNN once\n",
        "            GNN_features = torch.vstack([G_dict[p] for p in pids]) #append to make examples\n",
        "            del G_dict #clear up memory\n",
        "            interface_features = torch.vstack([Ptrdict[p] for p in pids])\n",
        "            compound_features = torch.vstack([Ctrdict[c] for c in batch_cids])\n",
        "            #[GNN_model(All_ProteinData_dict[p]) for p in set_pids]\n",
        "            output = IPPI_Net(GNN_features,compound_features,interface_features)\n",
        "            V = np.min(list(classratio_dict.values()))\n",
        "            weights = toTensor(np.array([classratio_dict[p]/V if batch_labels[i]==1 else 1.0 for i,p in enumerate(pids)  ]))\n",
        "            criterion  = nn.BCEWithLogitsLoss(weight = None)\n",
        "            loss = criterion(output.flatten(), batch_labels.float().cuda())\n",
        "            Loss.append(loss.item())\n",
        "            #if np.median(Loss[-10:])<1e-1: terminated = True\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            early_stop_count += 1\n",
        "            #%% Validation/Testing (saves the best model in every 10 iterations over the validation set)\n",
        "            GNN_model.eval()\n",
        "            IPPI_Net.eval()\n",
        "            Z, Y = [], []\n",
        "            with torch.no_grad():\n",
        "                for (batch_pids,batch_cids),batch_labels in test_loader:\n",
        "                    pids = [p.split('_')[0] for p in batch_pids]\n",
        "                    G_dict = {p:GNN_model(All_ProteinData_dict[p]) for p in set(pids)} #pass each unique complex through the GNN once\n",
        "                    GNN_features = torch.vstack([G_dict[p] for p in pids]) #append to make examples\n",
        "                    del G_dict #clear up memory\n",
        "                    interface_features = torch.vstack([Pttdict[p] for p in pids])\n",
        "                    compound_features = torch.vstack([Cttdict[c] for c in batch_cids])\n",
        "                    output = IPPI_Net(GNN_features,compound_features,interface_features)\n",
        "                    Z.extend(output.cpu().flatten().numpy())\n",
        "                    Y.extend(batch_labels.cpu().flatten().numpy())\n",
        "                aucroc = roc_auc_score(np.array(Y), np.array(Z))\n",
        "                aucpr = average_precision_score(Y,Z)\n",
        "                if aucroc>best_result:\n",
        "                    early_stop_count = 0\n",
        "                    best_result = aucroc\n",
        "                    best_model = (GNN_model.state_dict(),IPPI_Net.state_dict())\n",
        "                    IPPI_Net.load_state_dict(best_model[1])#path+'/newIPPI_Net_'+test[0][0].split('_')[0]+'_AUC_'+str (round (best_result,3)))#torch.load(path+'IPPI_Net_'+ Mcomplexname)[1])\n",
        "                    GNN_model.load_state_dict(best_model[0])\n",
        "                    GNN_model.eval()\n",
        "                    IPPI_Net.eval()\n",
        "                    Zb, Yb = [], []\n",
        "                    for (batch_pids,batch_cids),batch_labels in test_loader:\n",
        "                      pids = [p.split('_')[0] for p in batch_pids]\n",
        "                      G_dict = {p:GNN_model(All_ProteinData_dict[p]) for p in set(pids)} #pass each unique complex through the GNN once\n",
        "                      GNN_features = torch.vstack([G_dict[p] for p in pids]) #append to make examples\n",
        "                      del G_dict #clear up memory\n",
        "                      interface_features = torch.vstack([Pttdict[p] for p in pids])\n",
        "                      compound_features = torch.vstack([Cttdict[c] for c in batch_cids])\n",
        "                      bestmodeloutput=IPPI_Net(GNN_features,compound_features,interface_features)\n",
        "                      #torch.save(Loss, path+'/Loss_'+test[0][0].split('_')[0])\n",
        "                      Zb.extend(bestmodeloutput.cpu().flatten().numpy())\n",
        "                      Yb.extend(batch_labels.cpu().flatten().numpy())\n",
        "                    aucrocb = roc_auc_score(np.array(Yb), np.array(Zb))\n",
        "                    aucprb = average_precision_score(Yb,Zb)\n",
        "                    print('LOADED BEST AUCROC',aucrocb,'AUCPR',aucprb)#,'best aucroc')\n",
        "                    aucpr = average_precision_score(Y,Z)\n",
        "                    print('AUCROC',aucroc,'AUCPR',aucpr,'best aucroc',best_result)\n",
        "    ###Load best model\n",
        "    print (\"OUTSIDE LOOP AUC of Best\")\n",
        "    torch.save(best_model[1], path+'/GNN-based-pipeline_IPPI_Net_'+ test[0][0].split('_')[0])\n",
        "    torch.save(best_model[0], path+'/GNN-based-pipeline_GNN_model_'+ test[0][0].split('_')[0])\n",
        "    Zlist.extend(Zb);Ylist.extend(Yb)\n",
        "    np.save(path+test[0][0].split('_')[0]+'Scores',Zb)\n",
        "    np.save(path+test[0][0].split('_')[0]+'Targets',Yb)\n",
        "    aucrocb = roc_auc_score(np.array(Yb), np.array(Zb))\n",
        "    aucprb = average_precision_score(Yb,Zb)\n",
        "    print('Complex name',test[0][0].split('_')[0],'AUCROC',aucrocb,'AUCPR',aucprb)#,'best aucroc')\n",
        "\n",
        "    # ========================================\n",
        "    # EXTERNAL VALIDATION (Enabled by Default)\n",
        "    # ========================================\n",
        "    try:\n",
        "        print(f\"\\nExternal validation for {test_complex_name}...\")\n",
        "\n",
        "        # Test on Recent Publications\n",
        "        External_score, External_labels = PredictScorefromFile(\n",
        "            githubpath + '/Data/External data/2dyh_all.txt',\n",
        "            githubpath + '/Data/External data/pdb/',\n",
        "            Pscaler, Cscaler, IPPI_Net, GNN_model, test_complex_name)\n",
        "\n",
        "        ExternalscoresLOCO.extend(External_score)\n",
        "        Externallabels.extend(External_labels)\n",
        "        External_Auc = roc_auc_score(External_labels, External_score)\n",
        "        External_AP = average_precision_score(External_labels, External_score)\n",
        "        print(f\"  Recent Pubs - AUC-ROC: {External_Auc:.3f}, AUC-PR: {External_AP:.3f}\")\n",
        "\n",
        "        # Test on COVID-19\n",
        "        Covid19_External_score, Covid19_External_labels = PredictScorefromFile(\n",
        "            githubpath + '/Data/External data/HansonACE2hits.txt',\n",
        "            githubpath + '/Data/External data/pdb/',\n",
        "            Pscaler, Cscaler, IPPI_Net, GNN_model, test_complex_name)\n",
        "\n",
        "        covid19_Externallabels.extend(Covid19_External_labels)\n",
        "        covid19_ExternalscoresLOCO.extend(Covid19_External_score)\n",
        "        Covid19_External_Auc = roc_auc_score(Covid19_External_labels, Covid19_External_score)\n",
        "        Covid19_External_AP = average_precision_score(Covid19_External_labels, Covid19_External_score)\n",
        "        print(f\"  COVID-19 - AUC-ROC: {Covid19_External_Auc:.3f}, AUC-PR: {Covid19_External_AP:.3f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠️  External validation failed: {e}\")\n",
        "        print(f\"     Continuing with cross-validation results...\")\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(Ylist, Zlist)\n",
        "Auc = roc_auc_score(Ylist, Zlist)\n",
        "Auc=(Auc).round(2)\n",
        "# calculate precision-recall curve\n",
        "Zlist=np.array(Zlist);Yo=np.array(Ylist);\n",
        "#Y_t=np.array(Y_t);Y_score=np.array(Y_score)\n",
        "precision, recall, thresholds = precision_recall_curve(Ylist, Zlist)\n",
        "aucpr=average_precision_score (Ylist, Zlist)\n",
        "########\n",
        "np.save(path+'GNN-pipeline_Targets.npy',Ylist)\n",
        "np.save(path+'GNN-pipeline_Scores.npy',Zlist)\n",
        "######+\n",
        "fig = plt.figure()\n",
        "plt.plot(recall,precision,color='m',marker=',',label='AUC-PR:{: .2f}'.format(aucpr))\n",
        "plt.title('AUC-PR');plt.xlabel('recall');plt.ylabel('precision');plt.grid();plt.legend();plt.show();\n",
        "fig .savefig(path+\"GNN-pipeline AUC-PR for PPI Inhibitors.pdf\", bbox_inches='tight')\n",
        "###\n",
        "aucpr=(aucpr).round(2)\n",
        "print(\"AucROC and aucpr Over all complexes \\n\",Auc,\"\\n\",aucpr,\"\\ntotal P:N ration 1:\",int (np.sum([Yo==-1.0])/np.sum([Yo==1.0])))#,\"\\n\")\n",
        "#######\n",
        "fig = plt.figure()\n",
        "plt.plot(fpr,tpr,color='k',marker='d',label='AUC:{: .2f}'.format(Auc))\n",
        "plt.title('AUCROC');plt.xlabel('FPR');plt.ylabel('TPR');plt.grid();plt.legend();plt.show();\n",
        "fig .savefig(path+\"GNN-pipeline AUCROC for vPPI Inhibitors.pdf\", bbox_inches='tight')\n",
        "###\n",
        "print(\"Final average over all folds,Leave one complex out\",np.average(AUC_ROC_final).round(4),'±',np.std( AUC_ROC_final).round(4),np.average(Avg_P_final).round(4),'±',np.std( Avg_P_final).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final average over all folds,Leave one complex out\",np.average(AUC_ROC_final).round(4),'±',np.std( AUC_ROC_final).round(4),np.average(Avg_P_final).round(4),'±',np.std( Avg_P_final).round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGCpIm336IUs",
        "outputId": "a15f17cb-138e-40a9-ab81-475f963d388c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final average over all folds,Leave one complex out nan ± nan nan ± nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlgI8EnYxPoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "0cb3ab3d-385a-42af-d773-7be8dab048df"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/GNN-PPI-Inhibitor/onlyGearnet_Scores.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2007139325.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgithubpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/GNN-PPI-Inhibitor/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/PPI-Inhibitors/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mZ_GearNet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'onlyGearnet_Scores.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mYo_GearNet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'onlyGearnet_Targets.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/GNN-PPI-Inhibitor/onlyGearnet_Scores.npy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score,roc_curve,precision_score,recall_score,average_precision_score,precision_recall_curve,auc\n",
        "import matplotlib.pyplot as plt\n",
        "path,githubpath='/content/drive/MyDrive/GNN-PPI-Inhibitor/','/content/PPI-Inhibitors/'\n",
        "Z_GearNet=np.load(path+'onlyGearnet_Scores.npy')\n",
        "Yo_GearNet=np.load(path+'onlyGearnet_Targets.npy')\n",
        "####\n",
        "fpr_GearNet, tpr_GearNet, thresholds_GearNet = roc_curve(Yo_GearNet, Z_GearNet)\n",
        "Auc_GearNet = roc_auc_score(Yo_GearNet, Z_GearNet)\n",
        "Auc_GearNet=(Auc_GearNet).round(2)\n",
        "# calculate precision-recall curve\n",
        "precision_GearNet, recall_GearNet, thresholds = precision_recall_curve(Yo_GearNet, Z_GearNet)\n",
        "aucpr_GearNet=auc(recall_GearNet,precision_GearNet)\n",
        "aucpr_GearNet=(aucpr_GearNet).round(2)\n",
        "#######here svm\n",
        "# Yo_SVM=np.load(path+'All_SVM_Targets.npy')\n",
        "# Z_SVM=np.load(path+'All_SVM_Scores.npy')\n",
        "####here svm\n",
        "# fpr_SVM, tpr_SVM, thresholds_SVM = roc_curve(Yo_SVM, Z_SVM)\n",
        "# Auc_SVM = roc_auc_score(Yo_SVM, Z_SVM)\n",
        "# Auc_SVM=(Auc_SVM).round(2)\n",
        "# calculate precision-recall curve here svm\n",
        "# precision_SVM, recall_SVM, thresholds = precision_recall_curve(Yo_SVM, Z_SVM)\n",
        "# aucpr_SVM=auc(recall_SVM,precision_SVM)\n",
        "# aucpr_SVM=(aucpr_SVM).round(2)\n",
        "#####Change this\n",
        "Yo_GNN=np.load(path+'GNN-pipeline_Targets.npy')\n",
        "Z_GNN=np.load(path+'GNN-pipeline_Scores.npy')\n",
        "##########\n",
        "fpr_GNN, tpr_GNN, thresholds_GNN = roc_curve(Yo_GNN, Z_GNN)\n",
        "Auc_GNN= roc_auc_score(Yo_GNN, Z_GNN)\n",
        "Auc_GNN=(Auc_GNN).round(2)\n",
        "# calculate precision-recall curve\n",
        "precision_GNN, recall_GNN, thresholds = precision_recall_curve(Yo_GNN, Z_GNN)\n",
        "aucpr_GNN=auc(recall_GNN,precision_GNN)\n",
        "aucpr_GNN=(aucpr_GNN).round(2)\n",
        "###### GNN LOCO average 0.8576 ± 0.0923 0.4366 ± 0.2003\n",
        "##### SVM LOCO average 0.7445 ± 0.1958 0.3312 ± 0.2017\n",
        "fig = plt.figure()\n",
        "Auc_GNN_std,PR_GNN_std,Auc_SVM_std,PR_SVM_std=0.0923,0.01,0.16,0.18\n",
        "Auc_GearNet_std,PR_GearNet_std=0.1,0.19\n",
        "#text=\"There is an upcoming task in %d days at %d cluster!\" %a %cluster\n",
        "plt.plot(fpr_GNN,tpr_GNN,color='m',marker=',',markersize=2,label = ('GNN AUC-ROC : $ {} ± {}$').format(round(Auc_GNN,2), round(Auc_GNN_std,2)))\n",
        "#heresvm plt.plot(fpr_SVM,tpr_SVM,color='b',marker=',',markersize=2,label=('SVM AUC-ROC : $ {} ± {}$').format(round(Auc_SVM,2), round(Auc_SVM_std,2)))\n",
        "plt.plot(fpr_GearNet,tpr_GearNet,color='k',marker='.', markersize=3,label=('GearNet AUC-ROC : $ {} ± {}$').format(round(Auc_GearNet,2),round(Auc_GearNet_std,2)))\n",
        "plt.title('AUCROC');plt.xlabel('FPR');plt.ylabel('TPR');plt.grid();plt.legend();plt.show();\n",
        "fig .savefig(path+\"Comaprison of AUCROC SVM and GNN-base model PPI Inhibitors Random and Binders combine Negative.pdf\", bbox_inches='tight')\n",
        "#########\n",
        "fig = plt.figure()\n",
        "plt.plot(recall_GNN,precision_GNN,color='m',marker=',',markersize=2,label=('GNN AUC-PR : $ {} ± {}$').format(round(aucpr_GNN,2), round(PR_GNN_std,2)))\n",
        "#heresvm plt.plot(recall_SVM,precision_SVM,color='b',marker=',',markersize=2,label=('SVM AUC-PR: $ {} ± {}$').format(round(aucpr_SVM,2), round(PR_SVM_std,2)))\n",
        "plt.plot(recall_GearNet,precision_GearNet,color='k',marker='.', markersize=3,label=('GearNet AUC-PR: $ {} ± {}$').format(round(aucpr_GearNet,2), round(PR_GearNet_std,2)))\n",
        "plt.title('AUC-PR');plt.xlabel('Recall');plt.ylabel('Precision');plt.grid();plt.legend();plt.show();\n",
        "fig .savefig(path+\"Comaprison of AUC-PR SVM and GNN-base model PPI Inhibitors  Random and Binders combine.pdf\", bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "Y_score = np.array(Y_score)\n",
        "Y_t = np.array(Y_t)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(Y_t, Y_score)\n",
        "Auc = roc_auc_score(Y_t, Y_score)\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(Y_t, Y_score)\n",
        "aucpr = average_precision_score(Y_t, Y_score)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# AUC-ROC\n",
        "ax1.plot(fpr, tpr, color='k', marker='d', markersize=3, label=f'AUC: {Auc:.2f}')\n",
        "ax1.plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
        "ax1.set_xlabel('FPR', fontsize=12)\n",
        "ax1.set_ylabel('TPR', fontsize=12)\n",
        "ax1.set_title('AUC-ROC', fontsize=14, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# AUC-PR\n",
        "ax2.plot(recall, precision, color='m', marker=',', label=f'AUC-PR: {aucpr:.2f}')\n",
        "baseline = np.sum(Y_t) / len(Y_t)\n",
        "ax2.axhline(baseline, color='k', linestyle='--', alpha=0.3, label=f'Baseline: {baseline:.2f}')\n",
        "ax2.set_xlabel('Recall', fontsize=12)\n",
        "ax2.set_ylabel('Precision', fontsize=12)\n",
        "ax2.set_title('AUC-PR', fontsize=14, fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('ppi_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Results plotted\")"
      ],
      "metadata": {
        "id": "TaYf5rtlX-Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXTERNAL VALIDATION SUMMARY (Optional)\n",
        "# ============================================================================\n",
        "if len(ExternalscoresLOCO) > 0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXTERNAL VALIDATION - OVERALL RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Recent Publications\n",
        "    Overall_External_Auc = roc_auc_score(Externallabels, ExternalscoresLOCO)\n",
        "    Overall_External_AP = average_precision_score(Externallabels, ExternalscoresLOCO)\n",
        "\n",
        "    print(f\"\\nRecent Publications Dataset:\")\n",
        "    print(f\"  Examples: {len(Externallabels)}\")\n",
        "    print(f\"  AUC-ROC: {Overall_External_Auc:.3f}\")\n",
        "    print(f\"  AUC-PR:  {Overall_External_AP:.3f}\")\n",
        "    print(f\"  Expected: AUC-ROC ~0.82, AUC-PR ~0.45\")\n",
        "\n",
        "    # COVID-19\n",
        "    if len(covid19_ExternalscoresLOCO) > 0:\n",
        "        Overall_Covid19_Auc = roc_auc_score(covid19_Externallabels, covid19_ExternalscoresLOCO)\n",
        "        Overall_Covid19_AP = average_precision_score(covid19_Externallabels, covid19_ExternalscoresLOCO)\n",
        "\n",
        "        print(f\"\\nCOVID-19 ACE2 Inhibitors Dataset:\")\n",
        "        print(f\"  Examples: {len(covid19_Externallabels)}\")\n",
        "        print(f\"  AUC-ROC: {Overall_Covid19_Auc:.3f}\")\n",
        "        print(f\"  AUC-PR:  {Overall_Covid19_AP:.3f}\")\n",
        "        print(f\"  Expected: AUC-ROC ~0.78, AUC-PR ~0.42\")\n",
        "\n",
        "    # Plot external validation results\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Recent Publications\n",
        "    fpr, tpr, _ = roc_curve(Externallabels, ExternalscoresLOCO)\n",
        "    axes[0].plot(fpr, tpr, 'b-', linewidth=2,\n",
        "                 label=f'AUC-ROC: {Overall_External_Auc:.3f}')\n",
        "    axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
        "    axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
        "    axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
        "    axes[0].set_title('External: Recent Publications', fontsize=14, fontweight='bold')\n",
        "    axes[0].grid(alpha=0.3)\n",
        "    axes[0].legend()\n",
        "\n",
        "    # COVID-19\n",
        "    if len(covid19_ExternalscoresLOCO) > 0:\n",
        "        fpr, tpr, _ = roc_curve(covid19_Externallabels, covid19_ExternalscoresLOCO)\n",
        "        axes[1].plot(fpr, tpr, 'r-', linewidth=2,\n",
        "                     label=f'AUC-ROC: {Overall_Covid19_Auc:.3f}')\n",
        "        axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
        "        axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
        "        axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
        "        axes[1].set_title('External: COVID-19 ACE2', fontsize=14, fontweight='bold')\n",
        "        axes[1].grid(alpha=0.3)\n",
        "        axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('external_validation_results.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n✓ External validation complete!\")\n",
        "else:\n",
        "    print(\"\\n⚠️  External validation was not run\")\n",
        "    print(\"   (This is optional - cross-validation results are the main results)\")"
      ],
      "metadata": {
        "id": "nAfaCtAKYEzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNk6-cjzYxrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}